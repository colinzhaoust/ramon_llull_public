[["Scaling Reasoning with Contextually Grounded Language Models\n"], ["Title: Eliciting Faithful Reasoning via Contextual Decomposition in Transformer-Based Language Models\n"], ["Scaling Reasoning with Attention-Informed In-Context Learning\n"], ["Towards a Unified Framework for Reasoning with Language Models: Bridging In-Context Learning, Fine-tuning, and Emergent Abilities\n"], ["Title: Unveiling Implicit Reasoning Chains: A Fine-Grained Analysis of In-Context Learning in Large Language Models for Question Answering\n"], ["Title: Contextual Reasoning in Transformers: A Fine-Grained Analysis of In-Context Learning for Question Answering\n"], ["Contextualizing Attention: In-Context Learning Strategies for Enhanced Question Answering\n"], ["Rethinking Knowledge Integration: Adaptive In-Context Learning via Fine-Tuned Question Answering\n"], ["Calibrated In-Context Learning with Large Language Models: Bridging the Gap Between Prediction and Reality\n"], ["Calibrated In-Context Learning with Transformers: Bridging the Gap Between Prediction and Confidence\n"], ["Calibrated In-Context Learning via Attention Modulation for Reliable Language Model Generalization\n"], ["Calibrated In-Context Learning via Fine-Tuned Prompts: Bridging the Gap Between Prediction and Confidence\n"], ["Mitigating Unintended Consequences: Safety-Aware In-Context Learning for Large Language Models\n"], ["Contextualized Safety: Steering Transformer-Based Language Models via In-Context Learning for Robust and Reliable Natural Language Processing\n"], ["Attentive In-Context Learning for Safety-Critical Applications\n"], ["Towards Reliable and Safe Large Language Models: A Principled Framework for In-Context Learning and Safety-Aware Fine-tuning\n"], ["In-Context Meta-Research: Steering Automated Scientific Discovery with Large Language Models\n"], ["In-Context Meta-Research: Scaling Automated Scientific Discovery with Transformer Agents\n"], ["Towards Autonomous Scientific Discovery: In-Context Learning and Attention-Driven Exploration for Hypothesis Generation and Validation\n"], ["Scaling Automated Discovery with In-Context Learning and Targeted Fine-tuning\n"], ["Reasoning in the Wild: Benchmarking and Improving Compositional Generalization of Large Language Models in Unstructured Environments\n"], ["Reasoning with Transformers in Unstructured Environments: A Benchmark and Analysis\n"], ["Attentive Reasoning in the Wild: Benchmarking and Improving Robustness to Real-World Noise\n"], ["Reasoning in the Wild: Adaptive Fine-tuning for Open-Domain Inference\n"], ["Towards Robust and Explainable Open-Domain Question Answering: Benchmarking and Improving Large Language Models in Unconstrained Environments\n"], ["Robust Question Answering in Uncontrolled Environments: A Transformer-Based Approach with Adversarial Fine-Tuning and Uncertainty Estimation\n"], ["Context-Aware Attention for Open-Domain Question Answering in Unstructured Environments\n"], ["Towards Robust Open-Domain Question Answering: Fine-tuning Strategies for Real-World Scenarios\n"], ["Calibrating Large Language Models in Open-World Scenarios: A Novel Framework for Uncertainty-Aware Prediction\n"], ["Calibrating Transformers for Reliable Uncertainty Estimation in Real-World Natural Language Understanding\n"], ["Attentive Calibration in the Wild: Improving Reliability of Language Models Under Distribution Shift\n"], ["Calibrating Fine-tuned Language Models for Reliable In-the-Wild Performance\n"], ["Adversarial Resilience of Large Language Models in Unconstrained Environments: A Safety-Aware Evaluation Framework\n"], ["Robustness Under Real-World Perturbations: Evaluating and Improving Transformer Safety in Open-Domain Applications\n"], ["Robustifying Attention: In-the-Wild Adversarial Examples and Safety-Critical Applications\n"], ["Calibrating Open-World Language Models: Safety-Aware Fine-Tuning for Reliable Generalization\n"], ["LLMs as Autonomous Discovery Agents: In-the-Wild Scientific Experimentation and Knowledge Generation\n"], ["Autonomous Scientific Discovery with Transformers: A Reinforcement Learning Approach for In-the-Wild Experimentation\n"], ["Attention Landscapes: Discovering Novel Architectures through In-the-Wild, Automated Exploration\n"], ["Autonomous Scientific Discovery with Large Language Models: In-the-Wild Experimentation and Iterative Refinement\n"], ["Few-Shot Reasoning with Language Models via Iterative Self-Improvement\n"], ["Few-Shot Reasoning with Transformer-based Meta-Learners: A Curriculum Learning Approach\n"], ["Attentive Reasoning with Few-Shot Learning: Bridging Semantic Gaps in Low-Resource NLP\n"], ["Few-Shot Reasoning via Calibrated Fine-tuning of Language Models\n"], ["Few-Shot Question Answering with Knowledge-Augmented Large Language Models\n"], ["Few-Shot Question Answering with Meta-Learned Transformers: Bridging the Gap Between Semantic Similarity and Reasoning\n"], ["Attentive Probing for Few-Shot Question Answering: Unveiling Task-Specific Knowledge via Selective Contextualization\n"], ["Few-Shot Question Answering via Fine-Tuning with Contrastive Learning\n"], ["Few-Shot Calibration of Large Language Models: Bridging the Gap Between Prediction and Reality\n"], ["Few-Shot Calibration with Uncertainty-Aware Transformers\n"], ["Attentive Calibration for Robust Few-Shot Learning\n"], ["Few-Shot Learning via Calibrated Fine-tuning for Enhanced Generalization\n"], ["Few-Shot Learning with Safety Constraints for Robust and Reliable Large Language Models\n"], ["Safe Few-Shot Adaptation of Large Language Models via Uncertainty-Aware In-Context Learning\n"], ["Attentive Safety Augmentation for Robust Few-Shot Learning\n"], ["Mitigating Catastrophic Forgetting in Few-Shot Fine-Tuning for Safety-Critical Applications\n"], ["Few-Shot Scientific Discovery with Language Model Guided Experimentation\n"], ["Few-Shot Knowledge Discovery via Transformer-based Meta-Reasoning\n"], ["Attentive Meta-Learner for Automated Scientific Discovery in Low-Data Regimes\n"], ["Meta-Learned Fine-Tuning Strategies for Few-Shot Scientific Discovery\n"], ["Emergent Reasoning via Zero-Shot Chain-of-Thought with Language Model Augmented Knowledge Retrieval\n"], ["Title: Scaling Zero-Shot Reasoning via Emergent Modular Composition in Transformer-Based Language Models\n"], ["Attentive Reasoning for Zero-Shot Generalization: Bridging Semantic Gaps with Structured Knowledge\n"], ["Towards Open-World Reasoning: Bridging Zero-Shot Generalization and Few-Shot Adaptation\n"], ["Title: Reasoning-Augmented Zero-Shot Question Answering with Large Language Models\n"], ["Towards Robust Zero-Shot Question Answering: Mitigating Semantic Shift in Transformer-Based Models\n"], ["Attentional Probing for Robust Zero-Shot Question Answering: Unveiling Cross-Modal Semantic Alignment\n"], ["Bridging the Gap: Adaptive Fine-Tuning Strategies for Enhanced Zero-Shot Question Answering\n"], ["Calibrated Zero-Shot Learning with Large Language Models: Bridging Uncertainty and Generalization\n"], ["Calibrated Zero-Shot Transfer via Uncertainty-Aware Transformers\n"], ["Calibrated Attention for Reliable Zero-Shot Generalization in Natural Language Understanding\n"], ["Towards Reliable Zero-Shot Learning: Calibrating and Fine-Tuning Pre-trained Language Models\n"], ["Towards Safe and Generalizable Zero-Shot Learning: Mitigating Catastrophic Forgetting in Large Language Models\n"], ["Zero-Shot Generalization with Safety Constraints via Contrastive Learning in Transformer Architectures\n"], ["Zero-Shot Generalization with Attentional Safety Constraints\n"], ["Zero-Shot Generalization with Safety Constraints via Fine-Tuned Language Models\n"], ["Unsupervised Scientific Discovery via Zero-Shot Reasoning with Language Models\n"], ["Zero-Shot Scientific Discovery with Transformer-Based Reasoning\n"], ["Towards Autonomous Scientific Discovery: Zero-Shot Hypothesis Generation and Validation with Attentive Reasoning\n"], ["Towards Autonomous Scientific Discovery: Zero-Shot Hypothesis Generation and Experiment Design via Fine-Tuned Language Models\n"], ["Iterative Self-Improvement via Reasoning-Augmented Language Models\n"], ["Reasoning-Augmented Self-Refinement for Transformer-Based Language Models\n"], ["Reasoning-Augmented Self-Refinement via Adaptive Attention for Enhanced Language Understanding\n"], ["Iterative Self-Improvement via Reasoning-Augmented Fine-Tuning for Enhanced Language Model Performance\n"], ["Iterative Self-Improvement via Questioning and Reasoning in Large Language Models\n"], ["Iterative Self-Querying Transformers for Enhanced Reasoning and Question Answering\n"], ["Attentive Self-Refinement for Open-Domain Question Answering\n"], ["Iterative Self-Improvement via Question-Conditioned Fine-Tuning for Enhanced Language Model Reasoning\n"], ["Self-Refinement via Calibrated Decoding in Large Language Models\n"], ["Calibrated Self-Refinement via Uncertainty-Aware Transformers for Reliable Sequence Generation\n"], ["Attentive Self-Calibration for Reliable Neural Sequence Modeling\n"], ["Iterative Self-Improvement via Calibrated Fine-Tuning for Enhanced Language Model Performance\n"], ["Self-Refinement via Iterative Risk Minimization for Safer Large Language Models\n"], ["Iterative Self-Improvement of Transformer Safety via Adaptive Risk Modeling\n"], ["Attentive Self-Refinement for Safe and Robust Language Generation\n"], ["Iterative Self-Improvement with Safety Constraints: A Fine-Tuning Framework for Robust and Reliable Language Models\n"], ["Evolving Research Agendas: Self-Refinement of Hypotheses and Methodologies in Large Language Models\n"], ["Iterative Self-Improvement of Language Models for Scientific Discovery\n"], ["Iterative Self-Improvement via Attention-Guided Exploration for Scientific Discovery\n"], ["Evolving Research Agents: Autonomous Iteration of Hypotheses, Experiments, and Refinement\n"]]