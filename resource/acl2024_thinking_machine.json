{
    "A": {
        "In-Context Learning": [
            "in-context learning"
        ],
        "In-the-Wild": [
            "in-the-wild"
        ],
        "Few-Shot Learning": [
            "few-shot"
        ],
        "Zero-Shot Learning": [
            "zero-shot"
        ],
        "Self-Refinement": [
            "self-refine"
        ],
        "Multi-Hop Reasoning": [
            "multi-hop"
        ],
        "Self-Supervised Learning": [
            "self-supervised",
            "self-training"
        ],
        "Long-Tail Learning": [
            "long-tail"
        ],
        "Multi-Modal Learning": [
            "multi-modal",
            "multimodal",
            "cross-modal",
            "multi-modality",
            "modality"
        ],
        "Compositionality": [
            "compositionality"
        ],
        "Granularity": [
            "granularity",
            "fine-grained",
            "multi-granularity"
        ],
        "Low-Resource Learning": [
            "low-resource",
            "data-scarce",
            "resource-scarce",
            "small data",
            "data-scarce"
        ],
        "Evaluation": [
            "evaluation",
            "automatic evaluation",
            "evaluation framework",
            "measuring"
        ],
        "Alignment": [
            "alignment",
            "re-alignment",
            "preference alignment",
            "cultural alignment",
            "self-alignment"
        ],
        "Reference Free": [
            "reference free"
        ],
        "Self-Evolution": [
            "self-evolve"
        ],
        "Generalization": [
            "generalization",
            "generalizability",
            "generalizable",
            "domain generalization",
            "temporal generalization"
        ],
        "Robustness": [
            "robustness",
            "robust",
            "noise-robust",
            "ASR-Robust",
            "resilient"
        ],
        "Parameter-Efficient Learning": [
            "parameter-efficient",
            "parameter efficient"
        ],
        "Multilingual Learning": [
            "multilingual",
            "multi-lingual",
            "cross-lingual",
            "crosslingual"
        ],
        "Multi-Task Learning": [
            "multi-task",
            "multitask",
            "multi-task learning",
            "cross-task"
        ],
        "Bias": [
            "bias",
            "debiasing",
            "bias mitigation",
            "social bias",
            "position bias"
        ],
        "Modularity": [
            "modularity",
            "modular"
        ],
        "Less is More": [
            "less is more"
        ],
        "Adaptive Learning": [
            "adaptive",
            "domain-adaptive",
            "feature-adaptive",
            "adaptability",
            "unsupervised adaptation"
        ],
        "Data Augmentation": [
            "data augmentation",
            "augmentation",
            "Data Augmentation",
            "label augmentation",
            "rule augmentation",
            "knowledge augmentation"
        ],
        "Weak-to-Strong Generalization": [
            "weak to strong"
        ],
        "Contrastive Learning": [
            "contrastive learning",
            "contrastive"
        ],
        "Instruction Tuning": [
            "instruction tuning",
            "instruction-tuning",
            "instruction finetuning",
            "instruction-tuned"
        ],
        "Efficiency": [
            "efficiency",
            "efficient",
            "efficient training",
            "cost-effective"
        ],
        "Continual Learning": [
            "continual learning",
            "lifelong learning",
            "incremental learning",
            "catastrophic forgetting"
        ],
        "Explainability": [
            "explainable",
            "interpretability",
            "explainability",
            "explanation",
            "interpretable",
            "interpreting"
        ],
        "Distillation": [
            "distillation",
            "knowledge distillation",
            "self-distillation"
        ],
        "Unsupervised Learning": [
            "unsupervised",
            "weak supervision",
            "weakly supervised"
        ],
        "Hierarchical Learning": [
            "hierarchical"
        ],
        "Dynamic Learning": [
            "dynamic",
            "dynamics"
        ],
        "Mitigation": [
            "mitigation",
            "mitigating"
        ],
        "Adversarial Learning": [
            "adversarial"
        ],
        "Controllable Generation": [
            "controllable",
            "control",
            "steerability"
        ],
        "Multi-Agent Learning": [
            "multi-agent",
            "agent-based",
            "agent tuning",
            "agentic"
        ],
        "Survey": [
            "survey",
            "comprehensive",
            "comparative study",
            "holistic"
        ],
        "Iterative Learning": [
            "iterative",
            "iterative learning"
        ],
        "Rethinking": [
            "rethink"
        ],
        "Domain-Specific Learning": [
            "domain-specific",
            "specialized domains",
            "domain-adaptive"
        ],
        "Uncertainty": [
            "uncertainty",
            "uncertainty estimation"
        ],
        "Memory": [
            "memory",
            "long-term",
            "low-memory"
        ],
        "Long Context": [
            "long context",
            "long-context",
            "long sequence",
            "long documents"
        ],
        "Semi-Supervised Learning": [
            "semi-supervised",
            "weakly-supervised"
        ],
        "End-to-End Learning": [
            "end-to-end"
        ],
        "Compression": [
            "compression"
        ],
        "Optimization": [
            "optimization",
            "inner optimization"
        ],
        "Fairness": [
            "fairness"
        ],
        "Benchmark": [
            "benchmark",
            "benchmarks",
            "standardized"
        ],
        "Diversity": [
            "diversity",
            "diverse"
        ],
        "Active Learning": [
            "active learning",
            "active-learning"
        ],
        "Automatic": [
            "automatic",
            "automated",
            "automation"
        ],
        "Transfer Learning": [
            "transfer learning",
            "knowledge transfer",
            "transferability",
            "transferable",
            "transfer",
            "cross-lingual transfer",
            "task transfer",
            "domain transfer",
            "crosslingual transfer",
            "transferrable"
        ],
        "Commonsense Reasoning": [
            "commonsense reasoning",
            "commonsense"
        ],
        "Consistency": [
            "consistency",
            "self-consistency"
        ],
        "Adaptation": [
            "adaptation",
            "adaption"
        ],
        "Synthetic Data": [
            "synthetic data",
            "synthetic data generation",
            "synthesized data",
            "synthetic"
        ],
        "Quantization": [
            "quantization"
        ],
        "Ensemble Learning": [
            "ensemble"
        ],
        "Instruction Following": [
            "instruction-following",
            "instruction-aware",
            "instruction-based"
        ],
        "Large-Scale Learning": [
            "large-scale",
            "data-scalable",
            "scalable"
        ],
        "Unified": [
            "unified",
            "unifying approach",
            "all-in-one"
        ],
        "Universal": [
            "universal"
        ],
        "Multi-Turn Dialogue": [
            "multi-turn",
            "multi-round"
        ],
        "Privacy": [
            "privacy"
        ],
        "Out-of-Distribution": [
            "out-of-distribution",
            "out-domain",
            "out-of-KB",
            "open-set"
        ],
        "Data-Efficient Learning": [
            "data-efficient",
            "data-free"
        ],
        "Sparsity": [
            "sparse",
            "sparsity",
            "sparse training",
            "sparse representation learning"
        ],
        "Counterfactual Reasoning": [
            "counterfactual",
            "causal effect"
        ],
        "Curriculum Learning": [
            "curriculum learning"
        ],
        "Chain-of-Thought Prompting": [
            "chain-of-thought",
            "chain of thought",
            "step-by-step"
        ],
        "Collaborative Learning": [
            "collaborative",
            "collaborative learning",
            "cooperative",
            "cooperation",
            "co-learning"
        ],
        "Disentanglement": [
            "disentanglement"
        ],
        "Probing": [
            "probing"
        ],
        "Long-Term Learning": [
            "long-term"
        ],
        "Perturbation": [
            "perturbation"
        ],
        "Personalization": [
            "personalization",
            "individual differences",
            "customized"
        ],
        "Meta-Learning": [
            "meta-learning",
            "meta-training",
            "metaheuristics"
        ],
        "Non-Autoregressive Generation": [
            "non-autoregressive",
            "auto-regressive"
        ],
        "In-Domain": [
            "in-domain"
        ],
        "Multi-Label Classification": [
            "multi-label"
        ],
        "Temporal Learning": [
            "temporal",
            "time-aware"
        ],
        "Understanding": [
            "understanding"
        ],
        "Preference Learning": [
            "preference learning",
            "preference",
            "human preference",
            "multi-preference",
            "preference-based"
        ],
        "Multi-Objective Optimization": [
            "multi-objective"
        ],
        "Contextual Learning": [
            "contextual",
            "context-aware",
            "context-dependent",
            "history-aware",
            "topological context learning",
            "context awareness"
        ],
        "Streaming Data": [
            "streaming",
            "continuous"
        ],
        "Inductive Bias": [
            "inductive bias"
        ],
        "Selection": [
            "selection",
            "data selection",
            "annotation selection",
            "exemplar selection"
        ],
        "Representation Learning": [
            "representation learning",
            "representation engineering",
            "representation",
            "sparse representation learning",
            "latent",
            "binary representation"
        ],
        "Incremental Learning": [
            "incremental"
        ],
        "Simulation": [
            "simulation"
        ],
        "Plug-and-Play": [
            "plug-and-play",
            "plugin"
        ],
        "Look-Ahead": [
            "look-ahead"
        ],
        "Correlation": [
            "correlation",
            "spurious correlation"
        ],
        "Data Generation": [
            "data generation"
        ],
        "Multi-Dimensional": [
            "multi-dimensional"
        ],
        "Semantic Change Detection": [
            "semantic change detection"
        ],
        "Extrapolation": [
            "extrapolation"
        ],
        "Causal Inference": [
            "causal",
            "causal inference"
        ],
        "Backdoor Attack": [
            "backdoor",
            "backdoor attack"
        ],
        "Trade-Off": [
            "trade-off"
        ],
        "Relevance": [
            "relevance"
        ],
        "Label-Efficient Learning": [
            "label-efficient"
        ],
        "Self-Attention": [
            "self-attention"
        ],
        "Jailbreak": [
            "jailbreak"
        ],
        "Inconsistency": [
            "inconsistency"
        ],
        "Defense": [
            "defense",
            "self-defense"
        ],
        "Model-Agnostic": [
            "model-agnostic",
            "task-agnostic"
        ],
        "Heterogeneous Data": [
            "heterogeneous"
        ],
        "Tool Learning": [
            "tool learning",
            "tool using",
            "tool-integrated"
        ],
        "Structure": [
            "structure",
            "graph-structured"
        ],
        "Knowledge-Intensive Tasks": [
            "knowledge-intensive"
        ],
        "Emergent Properties": [
            "emergent"
        ],
        "Reproducibility": [
            "reproducible"
        ],
        "Self-Correction": [
            "self-correction"
        ],
        "Specialization": [
            "specialization",
            "speciality",
            "specialized domains"
        ],
        "Prompt Engineering": [
            "prompt engineering",
            "prompt-tuning",
            "prompt injection",
            "prompting"
        ],
        "Open Source": [
            "open source",
            "open-source",
            "open-sourcing"
        ],
        "Acceleration": [
            "acceleration"
        ],
        "Multi-View Learning": [
            "multi-view",
            "multi-perspective"
        ],
        "Non-Parametric Methods": [
            "non-parametric"
        ],
        "Knowledge": [
            "knowledge",
            "knowledge-enhanced",
            "knowledge-driven",
            "knowledge-infused",
            "knowledge reasoning",
            "knowledge retention",
            "knowledge synthesis",
            "knowledge recall",
            "knowledge-augmented"
        ],
        "Noisy Labels": [
            "noisy labels",
            "noise correction",
            "noise filtering",
            "noise reduction"
        ],
        "Transfer": [
            "transfer"
        ],
        "Reliability": [
            "reliability"
        ],
        "Implicit": [
            "implicit"
        ],
        "Graph-Based Methods": [
            "graph-based"
        ],
        "High-Quality Data": [
            "high-quality",
            "data quality"
        ],
        "Generative Models": [
            "generative",
            "conditional generation"
        ],
        "Trustworthiness": [
            "trustworthy"
        ],
        "Paraphrasing": [
            "paraphrasing",
            "paraphrase"
        ],
        "Cross-Cultural": [
            "cross-cultural"
        ],
        "Imbalance Data": [
            "imbalance"
        ],
        "Conditioning": [
            "conditioning"
        ],
        "Interactive Learning": [
            "interactive"
        ],
        "Simultaneous Learning": [
            "simultaneous",
            "Simultaneous"
        ],
        "Representation": [
            "representation"
        ],
        "Multi-Domain Learning": [
            "multi-domain",
            "cross-domain",
            "multigenre"
        ],
        "Attribution": [
            "attribution"
        ],
        "Grounding": [
            "grounding",
            "grounded generation"
        ],
        "Disambiguation": [
            "disambiguation"
        ],
        "Real-Time": [
            "real-time"
        ],
        "Fusion": [
            "fusion"
        ],
        "Influence": [
            "influence"
        ],
        "Collaboration": [
            "collaboration"
        ],
        "Synergy": [
            "synergy"
        ],
        "Verification": [
            "verification"
        ],
        "Subjective": [
            "subjective"
        ],
        "Mechanistic Analysis": [
            "mechanistic analysis"
        ],
        "Metric Learning": [
            "metric learning"
        ],
        "Consolidation": [
            "consolidation"
        ],
        "Interpolation": [
            "interpolation"
        ],
        "Asymmetric": [
            "asymmetric"
        ],
        "Language-Guided": [
            "language-guided"
        ],
        "Logic-Driven": [
            "logic-driven",
            "logical rules",
            "logical"
        ],
        "Nuanced": [
            "nuanced"
        ],
        "Low-Latency": [
            "low-latency"
        ],
        "Entropy": [
            "entropy"
        ],
        "Stereotypes": [
            "stereotypes"
        ],
        "Typicality": [
            "typicality"
        ],
        "Non-Monotonic": [
            "non-monotonic"
        ],
        "Multi-Stage": [
            "multi-stage"
        ],
        "Self-Explanation": [
            "self-explanation"
        ],
        "Pedagogical": [
            "pedagogical",
            "pedagogy-inspired"
        ],
        "Simplicity": [
            "simplicity"
        ],
        "Versatility": [
            "versatility"
        ],
        "Order-Agnostic": [
            "order-agnostic"
        ],
        "Post-Processing": [
            "post-processing"
        ],
        "Argumentative": [
            "argumentative"
        ],
        "Code Generation": [
            "code-generation"
        ],
        "Regularization": [
            "regularization"
        ],
        "Minimum Description Length": [
            "minimum description length"
        ],
        "Budget Constraint": [
            "budget constraint",
            "budget-constrained"
        ],
        "Attack": [
            "attack",
            "backdoor attack"
        ],
        "Misleading": [
            "misleading"
        ],
        "Generate-Then-Retrieve": [
            "generate-then-retrieve"
        ],
        "Estimation": [
            "estimation",
            "error estimation"
        ],
        "Curated Data": [
            "curated"
        ],
        "Partial Labels": [
            "partial labels"
        ],
        "Mechanism": [
            "mechanism"
        ],
        "Demonstration": [
            "demonstration"
        ],
        "On-Device": [
            "on-device",
            "mobile"
        ],
        "Early-Stage": [
            "early-stage",
            "early exit"
        ],
        "Distribution-Aware": [
            "distribution-aware"
        ],
        "Black-Box": [
            "black-box"
        ],
        "Data Contamination": [
            "data contamination"
        ],
        "Impact Analysis": [
            "impact analysis"
        ],
        "Unseen Data": [
            "unseen"
        ],
        "Complexity": [
            "complexity",
            "complex"
        ],
        "Knowledge Diversity": [
            "knowledge diversity"
        ],
        "Guidance": [
            "guidance"
        ],
        "Self-Evaluating": [
            "self-evaluating",
            "self-assessment"
        ],
        "Accurate": [
            "accurate"
        ],
        "Compact": [
            "compact"
        ],
        "Cognitive": [
            "cognitive"
        ],
        "Infilling": [
            "infilling"
        ],
        "Task-Specific": [
            "task-specific"
        ],
        "Hyperbolic Geometry": [
            "hyperbolic"
        ],
        "Probabilistic": [
            "probabilistic"
        ],
        "Distributional Assumptions": [
            "distributional assumptions"
        ],
        "Data Rebalancing": [
            "data rebalancing"
        ],
        "Reversal": [
            "reversal"
        ],
        "Dense Information": [
            "dense information",
            "information density"
        ],
        "Fuzzy Set": [
            "fuzzy set"
        ],
        "Symbolic": [
            "symbolic",
            "Neural-Symbolic"
        ],
        "Multi-Document": [
            "multi-document"
        ],
        "Human-in-the-Loop": [
            "human-in-the-loop",
            "in-the-loop",
            "human-centered"
        ],
        "Reranking": [
            "reranking"
        ],
        "Fundamental Capabilities": [
            "fundamental capabilities"
        ],
        "Pragmatic": [
            "pragmatic"
        ],
        "Prototype Learning": [
            "prototype learning"
        ],
        "Coherence": [
            "coherence",
            "narrative coherence"
        ],
        "Plausible": [
            "plausible"
        ],
        "Parallel Computing": [
            "parallel"
        ],
        "Training-Free": [
            "training-free",
            "learning-free"
        ],
        "Explore-Exploit": [
            "explore-exploit"
        ],
        "Speculative Decoding": [
            "speculative decoding"
        ],
        "Scaling Laws": [
            "scaling laws"
        ],
        "Hyperparameter-Free": [
            "hyperparameter-free"
        ],
        "Multi-Prototype": [
            "multi-prototype"
        ],
        "Clusters": [
            "clusters"
        ],
        "Machine Learning": [
            "machine learning"
        ],
        "Integration": [
            "integration"
        ],
        "Factual Knowledge": [
            "factual"
        ],
        "Inner States": [
            "inner states"
        ],
        "Self-Regulation": [
            "self-regulation"
        ],
        "Lightweight Models": [
            "lightweight",
            "minimal",
            "compact"
        ],
        "Reformulation": [
            "reformulate"
        ],
        "Progressive Learning": [
            "progressive"
        ],
        "Adaption": [
            "adaption"
        ],
        "Novelty Detection": [
            "novel"
        ],
        "Topic Model": [
            "topic model"
        ],
        "Low-Dimensional": [
            "low-dimensional"
        ],
        "Over-Segmentation": [
            "over-segmentation"
        ],
        "Concept-Guided": [
            "concept-guided"
        ],
        "Modelling": [
            "modelling"
        ],
        "Approximation": [
            "approximation"
        ],
        "Distributed Computing": [
            "distributed"
        ],
        "Multi-Generator": [
            "multi-generator"
        ],
        "Degeneracy": [
            "degeneracy"
        ],
        "Emotion-Aware": [
            "emotion-aware"
        ],
        "Multi-Level": [
            "multi-level",
            "multi-scale"
        ],
        "Anomalous Data": [
            "anomalous"
        ],
        "Challenge": [
            "challenge",
            "challenging"
        ],
        "Weight-Sharing": [
            "weight-sharing"
        ],
        "Architecture Search": [
            "architecture search"
        ],
        "Modality-Aware": [
            "modality-aware",
            "modality missing",
            "modality gap"
        ],
        "Locality": [
            "locality"
        ],
        "Multi-Facet": [
            "multi-facet"
        ],
        "Variability": [
            "variability"
        ],
        "Monotonic": [
            "monotonic"
        ],
        "Communication": [
            "communication"
        ],
        "Multi-Group": [
            "multi-group"
        ],
        "Perspective-Aware": [
            "perspective-aware",
            "perspective taking"
        ],
        "Ethical Considerations": [
            "ethical considerations"
        ],
        "Cultural Dominance": [
            "cultural dominance"
        ],
        "Online Learning": [
            "Online Learning"
        ],
        "Component-Wise Analysis": [
            "component-wise analysis"
        ],
        "Statistical Analysis": [
            "statistical"
        ],
        "Fine-Tuning": [
            "fine-tune",
            "instruction finetuning"
        ],
        "Analysis": [
            "analysis",
            "component-wise analysis",
            "impact analysis",
            "mechanistic analysis"
        ],
        "Latent Space": [
            "latent space"
        ],
        "Vulnerability": [
            "vulnerability"
        ],
        "One-Shot Learning": [
            "one-shot"
        ],
        "Open-Set Recognition": [
            "open-set"
        ],
        "Self-Updating": [
            "self-updating"
        ],
        "Position-Oriented": [
            "position-oriented"
        ],
        "Ablation Study": [
            "ablation"
        ],
        "Fidelity": [
            "fidelity"
        ],
        "Self-Disclosure": [
            "self-disclosure"
        ],
        "Invariance": [
            "invariance"
        ],
        "Indirect": [
            "indirect"
        ],
        "Figurative Language": [
            "figurative language"
        ],
        "Scaling and Efficiency": [
            "scaling",
            "parameter efficiency",
            "low-cost",
            "low-budget",
            "parameter-free",
            "low-bit"
        ],
        "Data Quality": [
            "quality-aware",
            "contamination",
            "data leakage",
            "noisy label",
            "noisy data",
            "imbalanced"
        ],
        "Trust and Safety": [
            "trustworthiness",
            "safety-aware",
            "red-teaming",
            "poisoning attack",
            "over-defensiveness",
            "stealthy"
        ],
        "Learning Paradigms": [
            "pretraining",
            "online",
            "interactive learning",
            "co-supervision",
            "imitation learning",
            "Teacher-Student",
            "lifelong learning",
            "life-long learning"
        ],
        "Knowledge and Information": [
            "parametric knowledge",
            "information retention",
            "information-theoretic",
            "external knowledge",
            "knowledge learning",
            "knowledge integration",
            "knowledge-aware",
            "knowledge-grounded",
            "information fusion",
            "information theory"
        ],
        "Bias and Fairness": [
            "mitigating bias",
            "Debiasing",
            "simplicity bias"
        ],
        "Domain Adaptation": [
            "domain-adapted",
            "domain transfer",
            "task transfer",
            "domain-aware",
            "crosslingual transfer",
            "domain-transfer",
            "cross-source"
        ],
        "Sequence Length": [
            "long-sequence",
            "long-term dependencies"
        ],
        "Reasoning and Inference": [
            "numerical reasoning",
            "intermediate-reasoning"
        ],
        "Evaluation Metrics": [
            "systematic evaluation",
            "empirical study",
            "ablation study",
            "error analysis"
        ],
        "Feedback Mechanisms": [
            "feedback",
            "feedback loop",
            "human feedback"
        ],
        "Uncertainty and Confidence": [
            "uncertainty-aware",
            "confidence",
            "overconfidence"
        ],
        "Model Editing and Refinement": [
            "editing",
            "refine"
        ],
        "Data Scarcity": [
            "data scarcity",
            "low-annotation"
        ],
        "Model Understanding": [
            "interpretation",
            "explanation generation",
            "transparency",
            "scrutability"
        ],
        "Optimization Techniques": [
            "sparsify",
            "automatic optimization"
        ],
        "Decoding Strategies": [
            "constrained decoding",
            "decoding"
        ],
        "Study Type": [
            "systematic",
            "empirical study"
        ],
        "Model Ablation": [
            "ablation study"
        ],
        "Learning Type": [
            "interactive learning",
            "imitation learning",
            "lifelong learning"
        ],
        "Model Generalization": [
            "generalization",
            "downstream"
        ],
        "Knowledge Representation": [
            "neurosymbolic",
            "structure-aware"
        ],
        "Model Selection": [
            "demonstration selection"
        ],
        "Knowledge Type": [
            "parametric knowledge",
            "external knowledge"
        ],
        "Reasoning Type": [
            "numerical reasoning",
            "intermediate-reasoning"
        ],
        "Semantic Understanding": [
            "semantic",
            "lexical"
        ],
        "Model Complexity": [
            "mixture of experts",
            "linear",
            "low-rank"
        ],
        "Knowledge Source": [
            "external knowledge",
            "cross-source"
        ],
        "Other": [
            "recursive",
            "sufficient",
            "autonomous",
            "specialized",
            "structured",
            "user-friendly",
            "novelty",
            "contextualized",
            "self-augment",
            "self-consistent",
            "tradeoff",
            "multi-stakeholder",
            "mixup",
            "speculative",
            "sampling",
            "bilingual",
            "reevaluation",
            "emergence",
            "disagreement",
            "time-sensitive",
            "finetune",
            "multi-tasking",
            "decomposition",
            "question generation",
            "multi-reference",
            "forgetfulness",
            "implicit supervision",
            "exploration",
            "self-organizing",
            "limitations",
            "cross-modality",
            "diffusion",
            "global-scale",
            "learnability",
            "sensitivity",
            "social",
            "multi-factor",
            "library",
            "benchmark dataset",
            "persuasive",
            "subnetwork",
            "faithfulness",
            "free-text",
            "unlearning"
        ]
    },
    "B": {
        "Reasoning": [
            "reasoning",
            "logical reasoning",
            "causal reasoning",
            "mathematical reasoning",
            "narrative reasoning"
        ],
        "Question Answering": [
            "question answering",
            "visual question answering",
            "VQA",
            "KBQA",
            "question-answering"
        ],
        "Calibration": [
            "calibration"
        ],
        "Safety": [
            "safety",
            "Drug Safety"
        ],
        "Automated Research": [
            "automated research"
        ],
        "Argument Mining": [
            "argument mining"
        ],
        "Machine Translation": [
            "machine translation",
            "neural machine translation",
            "NMT",
            "simultaneous translation",
            "simultaneous machine translation",
            "machine translations",
            "machine translation evaluation",
            "Neural Machine Translation"
        ],
        "Summarization": [
            "summarization",
            "text summarization",
            "abstractive summarization",
            "dialogue summarization",
            "clinical text summarization",
            "speech summarization",
            "multi-document summarization",
            "summarisation"
        ],
        "Benchmarking": [
            "benchmarking",
            "benchmarks",
            "evaluation benchmark",
            "GLUE benchmark",
            "benchmark construction"
        ],
        "RAG": [
            "RAG"
        ],
        "Planning": [
            "planning"
        ],
        "Language Modeling": [
            "language modeling",
            "causal language modeling",
            "language modelling",
            "Language Modeling"
        ],
        "Code Generation": [
            "code generation"
        ],
        "Translation": [
            "translation"
        ],
        "Memorization": [
            "memorization"
        ],
        "Relation Extraction": [
            "relation extraction",
            "relation classification",
            "Relation Extraction"
        ],
        "Text Classification": [
            "text classification",
            "natural language classification",
            "sentence classification",
            "natural language classification",
            "multi-label classification",
            "hierarchical classification",
            "legal classification",
            "Text Classification"
        ],
        "Retrieval": [
            "retrieval",
            "information retrieval",
            "dense retrieval",
            "image retrieval",
            "image-text retrieval",
            "legal retrieval",
            "text-video retrieval"
        ],
        "Text Generation": [
            "text generation",
            "language generation",
            "natural language generation",
            "longform text generation",
            "long-form text generation",
            "response generation",
            "medical text generation",
            "clinical text data generation",
            "attributed text generation",
            "open-ended generation",
            "citation text generation",
            "text completion"
        ],
        "Sentiment Analysis": [
            "sentiment analysis",
            "aspect-based sentiment analysis",
            "emotion analysis",
            "sentiment classification",
            "Sentiment Analysis"
        ],
        "Knowledge Graph": [
            "knowledge graph",
            "knowledge graphs",
            "Knowledge Graph Embedding",
            "Knowledge Graph Completion",
            "knowledge graph construction",
            "Temporal Knowledge Graph Forecasting"
        ],
        "Generation": [
            "generation",
            "sequence generation",
            "content generation",
            "voice generation",
            "speech generation",
            "humor generation",
            "paraphrase generation",
            "keyphrase generation",
            "multimodal generation",
            "text-to-music generation",
            "automatic story generation",
            "question generation",
            "Referring Expression Generation",
            "human gesture generation",
            "sequence generation",
            "speech-to-text generation"
        ],
        "Instruction Tuning": [
            "instruction tuning"
        ],
        "Information Extraction": [
            "information extraction"
        ],
        "Fine-tuning": [
            "fine-tuning",
            "tuning"
        ],
        "Inference": [
            "inference",
            "natural language inference",
            "NLI"
        ],
        "Speech Recognition": [
            "speech recognition",
            "automatic speech recognition",
            "ASR",
            "automatic speech recognition"
        ],
        "Parsing": [
            "parsing",
            "semantic parsing",
            "discourse parsing",
            "dialogue discourse parsing",
            "syntax"
        ],
        "Dialogue": [
            "dialogue",
            "dialogue generation",
            "dialogue systems",
            "task-oriented dialogue",
            "medical dialogue",
            "persuasive dialogue",
            "dialogue understanding",
            "task-oriented dialogue systems",
            "medical dialogue generation"
        ],
        "Recommendation": [
            "recommendation",
            "recommendation systems",
            "conversational recommendation"
        ],
        "Named Entity Recognition": [
            "named entity recognition",
            "Named Entity Recognition",
            "entity recognition"
        ],
        "Classification": [
            "classification",
            "natural language classification",
            "sentence classification",
            "style classification"
        ],
        "Natural Language Understanding": [
            "natural language understanding",
            "NLU",
            "spoken language understanding",
            "language understanding",
            "Spoken Language Understanding",
            "multimodal language understanding"
        ],
        "Reading Comprehension": [
            "reading comprehension",
            "scientific comprehension"
        ],
        "Language Models": [
            "language models",
            "large language models"
        ],
        "Dialogue Generation": [
            "dialogue generation"
        ],
        "Instruction Following": [
            "instruction following",
            "embodied instruction following"
        ],
        "Hate Speech Detection": [
            "hate speech detection",
            "offensive language detection",
            "abusive language detection",
            "toxic speech detection"
        ],
        "Speech Translation": [
            "speech translation",
            "speech-to-speech translation"
        ],
        "Dialogue Systems": [
            "dialogue systems",
            "dialog systems",
            "dialogue system"
        ],
        "NLP": [
            "NLP",
            "natural language processing",
            "Natural Language Processing",
            "NLP tasks",
            "NLP applications"
        ],
        "Fact-checking": [
            "fact-checking",
            "fact checking"
        ],
        "Detection": [
            "detection",
            "error detection",
            "hallucination detection",
            "bias detection",
            "fake news detection",
            "machine-generated text detection",
            "toxicity detection",
            "error detection",
            "hallucination detection",
            "vulnerability detection",
            "humor detection",
            "sarcasm detection",
            "misinformation detection",
            "bot detection",
            "outlier detection"
        ],
        "Debate": [
            "debate",
            "debate evaluation"
        ],
        "Knowledge Editing": [
            "knowledge editing",
            "model editing"
        ],
        "Stance Detection": [
            "stance detection"
        ],
        "Event Extraction": [
            "event extraction"
        ],
        "Document Understanding": [
            "document understanding"
        ],
        "Vision-Language": [
            "vision-language",
            "Vision Language Tasks"
        ],
        "Grammatical Error Correction": [
            "grammatical error correction",
            "grammar error correction",
            "grammar correction"
        ],
        "Text-to-Image Generation": [
            "text-to-image generation",
            "text-to-image synthesis",
            "text-to-image"
        ],
        "Social Media": [
            "social media",
            "social media moderation"
        ],
        "Code Completion": [
            "code completion"
        ],
        "Dialogue State Tracking": [
            "dialogue state tracking"
        ],
        "Downstream Tasks": [
            "downstream tasks"
        ],
        "Entity Linking": [
            "entity linking"
        ],
        "Annotation": [
            "annotation",
            "annotation bias",
            "sequence annotation"
        ],
        "Emotion Recognition": [
            "emotion recognition",
            "emotion detection",
            "emotion"
        ],
        "Watermarking": [
            "watermarking"
        ],
        "Text Simplification": [
            "text simplification"
        ],
        "Knowledge Base": [
            "knowledge base"
        ],
        "Fact Verification": [
            "fact verification",
            "factuality",
            "factuality evaluation"
        ],
        "Education": [
            "education",
            "ESL education"
        ],
        "Topic Modeling": [
            "topic modeling"
        ],
        "Image Captioning": [
            "image captioning",
            "captioning"
        ],
        "Coreference Resolution": [
            "coreference resolution"
        ],
        "Linguistics": [
            "linguistics"
        ],
        "Training": [
            "training",
            "pretraining",
            "language model pretraining"
        ],
        "Security": [
            "security"
        ],
        "Speech Processing": [
            "speech processing"
        ],
        "Conversation": [
            "conversation",
            "conversational"
        ],
        "Causality": [
            "causality",
            "causality identification",
            "causal discovery"
        ],
        "Semantics": [
            "semantics",
            "lexical semantics"
        ],
        "Content Moderation": [
            "content moderation"
        ],
        "Role-Playing": [
            "role-playing",
            "role-playing agents"
        ],
        "Text-to-Speech": [
            "text-to-speech"
        ],
        "Theory of Mind": [
            "theory of mind"
        ],
        "Social Science": [
            "social science"
        ],
        "Bias Detection": [
            "bias detection"
        ],
        "Audio Processing": [
            "audio processing"
        ],
        "Image Classification": [
            "image classification"
        ],
        "OCR": [
            "OCR"
        ],
        "Emotion Analysis": [
            "emotion analysis"
        ],
        "Text Embedding": [
            "text embedding"
        ],
        "Semantic Textual Similarity": [
            "semantic textual similarity",
            "semantic text similarity",
            "Semantic Textual Similarity"
        ],
        "Human-Computer Interaction": [
            "human-computer interaction",
            "human-AI interaction",
            "human-bot interaction"
        ],
        "Grounding": [
            "grounding",
            "entity grounding"
        ],
        "Data-to-Text Generation": [
            "data-to-text generation",
            "Table-to-Text Generation",
            "KG-to-text"
        ],
        "Drug Discovery": [
            "drug discovery",
            "biomedical discovery"
        ],
        "Finance": [
            "finance",
            "equity research",
            "macroeconomics"
        ],
        "Tool Learning": [
            "tool learning",
            "tool use",
            "tool-using"
        ],
        "Metaphor Detection": [
            "metaphor detection",
            "metaphor interpretation"
        ],
        "Emotional Support": [
            "emotional support"
        ],
        "Psycholinguistics": [
            "psycholinguistics"
        ],
        "Low-Resource Language": [
            "low-resource language"
        ],
        "Data Visualization": [
            "data visualization"
        ],
        "Code Understanding": [
            "code understanding"
        ],
        "Debugging": [
            "debugging"
        ],
        "Game Playing": [
            "game playing",
            "game",
            "open-world games"
        ],
        "Narrative Understanding": [
            "narrative understanding"
        ],
        "Text Style Transfer": [
            "text style transfer",
            "style transfer"
        ],
        "Chatbot": [
            "chatbot",
            "conversational chatbots"
        ],
        "Medical": [
            "medical",
            "medical domain",
            "medical imaging",
            "medical diagnostics"
        ],
        "Authorship Attribution": [
            "authorship attribution"
        ],
        "Text Evaluation": [
            "text evaluation"
        ],
        "Speech": [
            "speech"
        ],
        "Grammar Induction": [
            "grammar induction"
        ],
        "Style Transfer": [
            "style transfer"
        ],
        "Mathematics": [
            "mathematics",
            "mathematical",
            "mathematical problem-solving"
        ],
        "Link Prediction": [
            "link prediction"
        ],
        "Robotics": [
            "robotics"
        ],
        "Intent Discovery": [
            "intent discovery"
        ],
        "Speech Synthesis": [
            "speech synthesis",
            "singing voice synthesis",
            "singing"
        ],
        "Sign Language Production": [
            "sign language production"
        ],
        "Language Identification": [
            "language identification"
        ],
        "Deployment": [
            "deployment",
            "serving"
        ],
        "Healthcare": [
            "healthcare"
        ],
        "Web Agent": [
            "web agent"
        ],
        "Decision Making": [
            "decision making"
        ],
        "Part-of-Speech Tagging": [
            "part-of-speech tagging"
        ],
        "Prompt Engineering": [
            "prompt engineering"
        ],
        "Diagnosis": [
            "diagnosis"
        ],
        "Image Editing": [
            "image editing"
        ],
        "Speech Emotion Recognition": [
            "speech emotion recognition"
        ],
        "Image Generation": [
            "image generation"
        ],
        "Narratives": [
            "narratives"
        ],
        "Adversarial Robustness": [
            "adversarial robustness"
        ],
        "Web Scraping": [
            "web scraping"
        ],
        "Text Analysis": [
            "text analysis"
        ],
        "Text Ranking": [
            "text ranking"
        ],
        "Historical Text": [
            "historical text",
            "digital history"
        ],
        "Legal Assessment": [
            "legal assessment"
        ],
        "API": [
            "API"
        ],
        "Graph Understanding": [
            "graph understanding"
        ],
        "Human Preferences": [
            "human preferences",
            "preference ratings",
            "preference prediction"
        ],
        "Input Method Editors": [
            "input method editors"
        ],
        "Cognitive Psychology": [
            "cognitive psychology",
            "computational psychology",
            "cognitive science"
        ],
        "Pronunciation Assessment": [
            "pronunciation assessment"
        ],
        "Instruction Datasets": [
            "instruction datasets"
        ],
        "Readability Assessment": [
            "readability assessment"
        ],
        "Identification": [
            "identification",
            "target identification"
        ],
        "Diacritization": [
            "diacritization"
        ],
        "Pun Generation": [
            "pun generation"
        ],
        "Event Linking": [
            "event linking",
            "event detection",
            "event prediction"
        ],
        "Preference Modeling": [
            "preference modeling"
        ],
        "News Analysis": [
            "news analysis"
        ],
        "Hallucination Reduction": [
            "hallucination reduction"
        ],
        "Privacy Policy": [
            "privacy policy"
        ],
        "Scientific Writing": [
            "scientific writing"
        ],
        "Game": [
            "game"
        ],
        "LLM Agents": [
            "LLM Agents"
        ],
        "Data Analysis": [
            "data analysis"
        ],
        "User Behavior Prediction": [
            "user behavior prediction"
        ],
        "Discourse Parsing": [
            "discourse parsing"
        ],
        "Word Alignment": [
            "word alignment"
        ],
        "Bioinformatics": [
            "bioinformatics"
        ],
        "Formal Language Learning": [
            "formal language learning",
            "language learning",
            "language acquisition"
        ],
        "User Satisfaction Estimation": [
            "user satisfaction estimation"
        ],
        "Ethics": [
            "ethics",
            "morality"
        ],
        "Social Intelligence": [
            "social intelligence"
        ],
        "Spelling Check": [
            "spelling check",
            "spelling correction",
            "grammar",
            "spelling correction"
        ],
        "Entailment": [
            "entailment"
        ],
        "Citation Analysis": [
            "citation analysis"
        ],
        "Software Development": [
            "software development",
            "automated programming"
        ],
        "Mental Health Text Analysis": [
            "mental health text analysis",
            "mental health monitoring"
        ],
        "Long Sequences": [
            "long sequences"
        ],
        "Image Understanding": [
            "Image Understanding",
            "multi-modal understanding"
        ],
        "Programming": [
            "programming"
        ],
        "Tool-Using": [
            "tool-using"
        ],
        "Knowledge Graph Forecasting": [
            "knowledge graph forecasting"
        ],
        "Text Mining": [
            "text mining"
        ],
        "Automated Essay Scoring": [
            "automated essay scoring"
        ],
        "Semantic Search": [
            "semantic search"
        ],
        "Editing": [
            "editing",
            "model editing"
        ],
        "Bilingual Lexicon Induction": [
            "bilingual lexicon induction"
        ],
        "Knowledge-Intensive Tasks": [
            "knowledge-intensive tasks"
        ],
        "Forecasting": [
            "forecasting",
            "time series forecasting",
            "trend analysis"
        ],
        "Task Performance": [
            "task performance"
        ],
        "Addiction Recovery": [
            "addiction recovery"
        ],
        "Jailbreak Defense": [
            "jailbreak defense"
        ],
        "Sequence Tagging": [
            "sequence tagging"
        ],
        "Medical Diagnostics": [
            "medical diagnostics"
        ],
        "Poll Generation": [
            "poll generation"
        ],
        "Hypernymy Detection": [
            "hypernymy detection"
        ],
        "Hiring Decisions": [
            "hiring decisions"
        ],
        "Document Management": [
            "document management"
        ],
        "Drug Safety": [
            "Drug Safety"
        ],
        "Paraphrase Generation": [
            "paraphrase generation"
        ],
        "N/A": [
            "N/A"
        ],
        "Keyphrase Generation": [
            "keyphrase generation",
            "keyphrase extraction"
        ],
        "Real-World Datasets": [
            "real-world datasets"
        ],
        "Text Augmentation": [
            "text augmentation",
            "dataset augmentation"
        ],
        "Embodied Tasks": [
            "embodied tasks",
            "embodied learning",
            "embodied agents"
        ],
        "Emotional Intelligence": [
            "Emotional Intelligence"
        ],
        "Ideology Detection": [
            "ideology detection"
        ],
        "Brain-Computer Interfaces": [
            "brain-computer interfaces"
        ],
        "Persuasive Dialogue": [
            "persuasive dialogue",
            "persuasion"
        ],
        "Intention Detection": [
            "intention detection",
            "intent detection"
        ],
        "Writing": [
            "writing",
            "writing assistance"
        ],
        "Search": [
            "search",
            "conversational search",
            "product search",
            "code search",
            "semantic search"
        ],
        "Mathematical Reasoning": [
            "mathematical reasoning"
        ],
        "Copyright": [
            "copyright"
        ],
        "Argument Generation": [
            "argument generation"
        ],
        "Few-Shot Learning": [
            "few-shot learning"
        ],
        "Radiology": [
            "radiology"
        ],
        "Taxonomy Expansion": [
            "taxonomy expansion"
        ],
        "Federated Learning": [
            "federated learning"
        ],
        "Attribute Recognition": [
            "attribute recognition"
        ],
        "Logic": [
            "logic"
        ],
        "Generative AI Evaluation": [
            "generative AI evaluation"
        ],
        "Image-Text Alignment": [
            "image-text alignment",
            "image-text matching"
        ],
        "Language Comprehension": [
            "language comprehension"
        ],
        "Knowledge Updating": [
            "knowledge updating",
            "knowledge injection"
        ],
        "Verification": [
            "verification"
        ],
        "Domain Applications": [
            "domain applications"
        ],
        "Cloud-Edge Collaboration": [
            "cloud-edge collaboration"
        ],
        "Model Pruning": [
            "model pruning",
            "pruning"
        ],
        "Address Standardization": [
            "address standardization"
        ],
        "Stereotyping": [
            "stereotyping"
        ],
        "Political Participation": [
            "political participation"
        ],
        "Dialogue Analysis": [
            "dialogue analysis"
        ],
        "Multi-Modality": [
            "multi-modality",
            "multimodal learning",
            "multimodal tasks"
        ],
        "Dataset Curation": [
            "dataset curation",
            "corpus construction",
            "subjective datasets"
        ],
        "Therapy": [
            "therapy"
        ],
        "Domain Generalization": [
            "domain generalization"
        ],
        "Knowledge Extraction": [
            "knowledge extraction"
        ],
        "Transparency": [
            "transparency"
        ],
        "Social Values": [
            "social values"
        ],
        "Common Knowledge": [
            "common knowledge"
        ],
        "Hateful Meme Detection": [
            "hateful meme detection"
        ],
        "Personality Assessment": [
            "personality assessment"
        ],
        "Protein Language": [
            "protein language",
            "protein-centric tasks",
            "protein-language tasks"
        ],
        "Navigation": [
            "navigation"
        ],
        "Explainable AI": [
            "explainable AI"
        ],
        "NAS": [
            "NAS"
        ],
        "Feedback": [
            "feedback"
        ],
        "Model Selection": [
            "model selection"
        ],
        "Novel Tasks": [
            "novel tasks"
        ],
        "Exploration": [
            "exploration"
        ],
        "Fallacy Recognition": [
            "fallacy recognition"
        ],
        "Intent Classification": [
            "Intent Classification"
        ],
        "Motion Analysis": [
            "motion analysis"
        ],
        "Controllable Generation": [
            "controllable generation"
        ],
        "Human Resource": [
            "human resource"
        ],
        "Legal Judgment Prediction": [
            "legal judgment prediction"
        ],
        "Sentence Embeddings": [
            "sentence embeddings"
        ],
        "Record Linkage": [
            "record linkage"
        ],
        "Data Cleaning": [
            "data cleaning"
        ],
        "Clinical Domain": [
            "clinical domain"
        ],
        "Slide Generation": [
            "slide generation"
        ],
        "Linguistic Acceptability": [
            "linguistic acceptability"
        ],
        "Negotiation": [
            "negotiation"
        ],
        "Biomedicine": [
            "biomedicine"
        ],
        "Intervention": [
            "intervention"
        ],
        "Long-Form Generation": [
            "long-form generation"
        ],
        "Semantic Role Labeling": [
            "Semantic Role Labeling"
        ],
        "Object Detection": [
            "object detection"
        ],
        "Temporal Knowledge Graph Forecasting": [
            "Temporal Knowledge Graph Forecasting"
        ],
        "Audio-Language": [
            "audio-language"
        ],
        "Multimodal Language Understanding": [
            "multimodal language understanding"
        ],
        "Tabular Data": [
            "tabular data"
        ],
        "Autonomous Driving": [
            "autonomous driving"
        ],
        "IoT": [
            "IoT"
        ],
        "Comparison": [
            "comparison"
        ],
        "Rationalization": [
            "rationalization"
        ],
        "Word Sense Disambiguation": [
            "word sense disambiguation"
        ],
        "Empathy Detection": [
            "empathy detection"
        ],
        "Data Leakage": [
            "data leakage"
        ],
        "Cybersecurity": [
            "cybersecurity"
        ],
        "Multi-Agent System": [
            "multi-agent system"
        ],
        "Clinical Notes": [
            "clinical notes"
        ],
        "Clinical Predictions": [
            "clinical predictions"
        ],
        "Normalization": [
            "normalization"
        ],
        "Ranking": [
            "ranking",
            "re-ranking",
            "text ranking"
        ],
        "Problem-Solving": [
            "problem-solving"
        ],
        "Subjective Tasks": [
            "subjective tasks"
        ],
        "Multi-Round Interactions": [
            "multi-round interactions"
        ],
        "Rumor Verification": [
            "rumor verification"
        ],
        "Speech Understanding": [
            "speech understanding"
        ],
        "Regression": [
            "regression"
        ],
        "Language Documentation": [
            "language documentation"
        ],
        "Morphological Inflection": [
            "morphological inflection"
        ],
        "Code Analysis": [
            "code analysis",
            "code understanding"
        ],
        "Automatic Subtitling": [
            "automatic subtitling"
        ],
        "Semantic Similarity": [
            "semantic relatedness",
            "semantic similarity"
        ],
        "Conversation AI": [
            "conversation AI",
            "conversational agents",
            "dialog modeling"
        ],
        "Speech Technology": [
            "speech-to-singing conversion",
            "Text-to-Speech",
            "speech-to-text translation",
            "voice conversion",
            "Voice Cloning",
            "speech editing",
            "audio generation"
        ],
        "Visual Understanding": [
            "visual grounding",
            "visual understanding",
            "visual reasoning"
        ],
        "Ethical AI": [
            "ethical decision-making",
            "trustworthiness",
            "stereotypes"
        ],
        "Model Security": [
            "satety",
            "red-teaming",
            "jailbreaking",
            "data contamination"
        ],
        "Code Processing": [
            "code translation",
            "code retrieval"
        ],
        "Knowledge": [
            "knowledge recall",
            "temporal knowledge graph"
        ],
        "Machine-Generated Content": [
            "machine-generated text",
            "verifiable generation"
        ],
        "NLG Evaluation": [
            "NLG evaluation",
            "model evaluation"
        ],
        "Reinforcement Learning": [
            "Reinforcement Learning from Human Feedback",
            "pre-training",
            "supervised fine-tuning"
        ],
        "Multilingual Processing": [
            "unsupervised word translation",
            "multilingual models",
            "NMT",
            "XNLI",
            "MLQA",
            "video translation"
        ],
        "Visual-Language Understanding": [
            "3D dense captioning",
            "video-language understanding",
            "image description",
            "visual grounding"
        ],
        "Human-AI Interaction": [
            "Human-AI communication",
            "social interaction"
        ],
        "Formal Language": [
            "formal languages",
            "string algorithms"
        ],
        "Other": [
            "empathetic communication",
            "visualization",
            "analysis",
            "GUI Agents",
            "task automation",
            "software verification",
            "semantic role labeling",
            "historical reconstruction",
            "binary classification",
            "misinformation research",
            "explanation generation",
            "slot filling",
            "attribute value extraction",
            "e-commerce",
            "customization",
            "recommender systems",
            "music generation",
            "cultural values",
            "music",
            "structured prediction",
            "teaching",
            "scientific literature",
            "Evidence-Based QA",
            "sign language translation",
            "hate speech",
            "Chinese Spelling Correction",
            "lexical gap detection",
            "lexicon construction",
            "semantics discovery",
            "social movement",
            "paraphrasing identification",
            "text representation",
            "image synthesis",
            "information verification",
            "copyright protection",
            "watermarks",
            "web search",
            "controlled generation",
            "Word Sense Disambiguation",
            "news",
            "demonstration system",
            "sign language processing",
            "document comprehension",
            "domain specialization"
        ]
    },
    "C": {
        "Large Language Models": [
            "LLMs",
            "Large Language Models",
            "Language Models",
            "pre-trained language models",
            "Pre-trained Language Models",
            "pretrained language models",
            "large pre-trained model",
            "Large Multimodal Language Models",
            "Multi-modal Large Language Models",
            "Multimodal Large Language Models",
            "pre-trained generation models",
            "generative language models",
            "Multi-Source Language Training",
            "Causal Language Models",
            "Prefix Language Models",
            "Small Language Models",
            "GPT",
            "foundation model",
            "foundation models",
            "SLMs"
        ],
        "Transformers": [
            "Transformers",
            "Transformer",
            "transformers",
            "transformer",
            "transformer-based neural networks",
            "Linear Transformers",
            "Transformer Models",
            "Transformer Language Models",
            "transformer-based models",
            "transformer architecture",
            "transformer architecture",
            "transformer layers",
            "transformer-based language Autoencoder",
            "transformer-based language models",
            "Rule-Transformer"
        ],
        "Attention Mechanisms": [
            "Self-attention",
            "attention mechanism",
            "Attention",
            "attention",
            "attention module",
            "attention heads",
            "attention bias",
            "fusion attention",
            "cross-attention",
            "attention-based models",
            "attention mechanisms",
            "Attention-based encoder-decoder networks"
        ],
        "Fine-tuning": [
            "LoRA",
            "Low-Rank Adaptation",
            "adapters",
            "PEFT",
            "Prompt Tuning",
            "prompt tuning",
            "parameter-efficient fine-tuning",
            "Parameter-efficient fine-tuning",
            "instruction finetuning",
            "weight tuning",
            "weight fusion",
            "finetuning",
            "Low-Rank Adapters"
        ],
        "Reinforcement Learning": [
            "RLHF",
            "Reinforcement Learning",
            "reinforcement learning",
            "RL",
            "PPO",
            "REINFORCE",
            "Direct Preference Alignment"
        ],
        "Embeddings": [
            "text embeddings",
            "embedding",
            "embeddings",
            "sentence embedding",
            "cross-lingual word embeddings",
            "concept embeddings",
            "embedding spaces",
            "clustering embeddings",
            "query representation learning",
            "word embeddings",
            "contextual word embeddings",
            "embedding model"
        ],
        "Vision-Language Models": [
            "vision-language models",
            "Large Vision-Language Models",
            "Vision-Language Models",
            "Large Multimodal Models",
            "Vision Language Models",
            "VLMs",
            "vision and language models",
            "GPT-4V",
            "LLaVA",
            "SigLIP",
            "BLIP",
            "video-text models",
            "cross-modal alignment",
            "modality alignment",
            "modality gap",
            "vision-language model"
        ],
        "Mixture of Experts": [
            "Mixture-of-Experts",
            "Mixture of Experts",
            "mixture-of-experts",
            "MoE"
        ],
        "Graph Neural Networks": [
            "graph neural networks",
            "Graph Neural Networks",
            "graph",
            "graph learning",
            "graph attention network",
            "graph convolutional networks",
            "Graph Neural Network",
            "graph convolutional network",
            "graph-based method",
            "graph algorithms",
            "graph models",
            "hypergraph",
            "hypernetworks",
            "Hypernetworks",
            "Abstract Syntax Tree",
            "entailment tree"
        ],
        "BERT Models": [
            "BERT",
            "BERT-like models",
            "RoBERTa",
            "BART",
            "ByT5",
            "T5"
        ],
        "Diffusion Models": [
            "diffusion models",
            "Diffusion Models",
            "diffusion model",
            "diffusion process",
            "Latent Diffusion Model",
            "Brownian Bridge process"
        ],
        "Pre-trained Models": [
            "pre-trained models",
            "pretrained models",
            "pretrained model",
            "pretrained language model",
            "pretrained weights",
            "PLMs",
            "PLM"
        ],
        "Neural Networks": [
            "neural networks",
            "Neural Networks",
            "neural models",
            "neural architecture",
            "neural architectures",
            "deep neural networks",
            "deep neural network",
            "neural network",
            "deep learning",
            "invertible neural networks",
            "Spiking Neural Network"
        ],
        "Generation Models": [
            "generation model",
            "generative models",
            "abstractive models",
            "text generation network",
            "text-to-image generative models",
            "instruction-based generative model",
            "Generative models"
        ],
        "Decoding": [
            "Decoding",
            "decoding algorithms",
            "speculative decoding",
            "tokenizer inference methods",
            "decoding algorithm",
            "decoding strategy",
            "contrastive decoding"
        ],
        "Contrastive Learning": [
            "Contrastive Learning",
            "contrastive loss",
            "contrastive pretraining",
            "contrastive hashing"
        ],
        "Model Training": [
            "model training",
            "model-based approach",
            "gradient descent",
            "loss function",
            "loss-based label correction",
            "two-stage training",
            "weight-space",
            "gradients"
        ],
        "Architectures": [
            "architectures",
            "neural architectures",
            "model architecture"
        ],
        "Frameworks": [
            "framework",
            "end-to-end framework",
            "unified framework",
            "rule-based framework",
            "Rational Speech Act framework",
            "toolkit"
        ],
        "Algorithms": [
            "algorithm",
            "algorithms"
        ],
        "Evaluation Metrics": [
            "metrics",
            "automated metrics",
            "automatic evaluation metrics",
            "neural metrics",
            "evaluation metrics",
            "n-gram-based metrics"
        ],
        "Sequence-to-Sequence Models": [
            "sequence-to-sequence models",
            "sequence-to-sequence model",
            "Encoder-Decoder",
            "Encoder-Decoder Models"
        ],
        "Variational Autoencoders": [
            "variational autoencoder",
            "VAE",
            "VAEs",
            "variational-autoencoding",
            "variational methods"
        ],
        "Retrieval": [
            "Retrieval",
            "dense retrieval",
            "neural retrieval",
            "classification-based retrieval",
            "Knowledge Retriever",
            "retrieval-augmented LLMs",
            "retrieval-augmented models",
            "re-ranking method"
        ],
        "Machine Translation": [
            "Machine Translation",
            "Simultaneous Machine Translation",
            "machine translation systems",
            "NMT"
        ],
        "Data": [
            "datasets",
            "data",
            "Synthetic Data"
        ],
        "None": [
            "None",
            "none"
        ],
        "Causal Inference": [
            "causal masking",
            "causal intervention"
        ],
        "RNNs": [
            "RNNs",
            "RNN",
            "LSTM"
        ],
        "N-gram Models": [
            "n-gram",
            "N-gram",
            "n-gram model",
            "n-gram-based metrics"
        ],
        "Agents": [
            "agent",
            "AI agent"
        ],
        "Optimal Transport": [
            "optimal transport",
            "Optimal Transport"
        ],
        "Code": [
            "code",
            "code language models"
        ],
        "Prompting": [
            "prompting strategies",
            "prompt",
            "prompt-learning",
            "prompting",
            "soft prompts",
            "prompt-based",
            "soft prompt",
            "prompt-driven",
            "Prompt Compression"
        ],
        "Linear Mapping": [
            "linear mapping",
            "linear probing"
        ],
        "Longformer Models": [
            "Longformer",
            "Longformer-Encoder-Decoder"
        ],
        "Adversarial Learning": [
            "adversarial learning",
            "Adversarial",
            "GANs",
            "discriminator"
        ],
        "Knowledge": [
            "structured knowledge",
            "external knowledge",
            "lexical knowledge"
        ],
        "Modality": [
            "modality",
            "cross-modal fusion",
            "Multimodal",
            "cross-modal fusion"
        ],
        "Attention Bias": [
            "attention bias",
            "attention mechanisms"
        ],
        "Non-Autoregressive Models": [
            "non-autoregressive decoder",
            "non-autoregressive models",
            "autoregressive models",
            "auto-regressive language models"
        ],
        "Bayesian Models": [
            "Bayesian Models",
            "Dirichlet Process",
            "Spectral Mixture Kernel"
        ],
        "Text Encoders": [
            "text encoders",
            "text encoding"
        ],
        "Audio Models": [
            "audio language models",
            "acoustic model",
            "speech encoders",
            "sound codec models",
            "spoken language model",
            "audio-visual models",
            "audio-visual"
        ],
        "Teacher-Student Models": [
            "teacher-student",
            "teacher-student model",
            "self-knowledge distillation"
        ],
        "Representation Learning": [
            "representation learning",
            "representation model",
            "distributed representation"
        ],
        "Rule-based Systems": [
            "rule-based methods",
            "rule-based system",
            "rule-based heuristic",
            "rule-based framework",
            "logical rules"
        ],
        "End-to-End Models": [
            "End-to-end",
            "end-to-end models"
        ],
        "Metrics": [
            "automated metrics",
            "automatic evaluation metrics",
            "neural metrics"
        ],
        "Search": [
            "dense retrieval",
            "neural retrieval"
        ],
        "Lexicons": [
            "lexicons",
            "bilingual lexicons"
        ],
        "Word Representations": [
            "distributed representation",
            "word embeddings"
        ],
        "Small Models": [
            "small models",
            "small language models"
        ],
        "Miscellaneous": [
            "Chain-of-Thought",
            "Chain-of-Thought prompting",
            "CLIP",
            "clustering",
            "framework",
            "algorithm",
            "pipeline",
            "data compression",
            "tokenizer",
            "tokenization",
            "corpus statistics",
            "features",
            "ensembles",
            "dynamic programming",
            "mutual information",
            "CTC",
            "measurement modeling",
            "co-training",
            "code-switching",
            "Knowledge Graph",
            "unified framework",
            "gradient descent",
            "NLP technology",
            "Rotary Position Embeddings",
            "randomization model",
            "graph structures",
            "MCTS",
            "multilingual embeddings",
            "weight-space",
            "gaze module",
            "randomization",
            "feedforward",
            "Layout-Aware",
            "context-aware models",
            "rewriting",
            "kNN",
            "k-Nearest-Neighbor",
            "k-nearest-neighbor",
            "character-level",
            "ChatGPT",
            "Lorentz transformation",
            "entailment tree",
            "internal states",
            "floating-point",
            "Formal Concept Analysis",
            "parsing-based syntactic dependencies",
            "geometric operations",
            "surprisal",
            "entropy",
            "function calling",
            "KV cache",
            "sampling",
            "dropout",
            "Zipfs Law",
            "counterfactual augmentation",
            "HMM",
            "Shapley values",
            "information dissemination",
            "scaling parameters",
            "preference optimization",
            "joint-learning",
            "finite-state machines",
            "Quantization",
            "adapters",
            "spelling correction model",
            "auxiliary task",
            "clustering",
            "Task Arithmetic",
            "Byte Pair Encoding",
            "Natural Language Inference",
            "pruning",
            "Fusion-in-Decoder",
            "self-supervised learning",
            "fastText",
            "interpolation augmentation",
            "spoken language model",
            "nonverbal communication",
            "sense-aware encoders",
            "Abstract Meaning Representation",
            "textual entailment",
            "parameter-efficient fine-tuning",
            "API simulators",
            "software quality",
            "bidirectional encoders",
            "two-stage training",
            "information bottleneck",
            "teacher-student",
            "agent",
            "ModelOps",
            "re-ranking method",
            "Siamese network",
            "Neural Transducer",
            "NLP methods",
            "Deep Neural Networks",
            "Deep Neural Network",
            "Structured Knowledge",
            "Abstractive models",
            "Abstract Syntax Tree",
            "contextual word embeddings",
            "geometric operations",
            "Rotary Position Embedding",
            "Spectral Mixture Kernel",
            "Optimal Transport",
            "auxiliary task",
            "Zipfs Law",
            "byT5",
            "ControlNet",
            "CTC",
            "parsing-based syntactic dependencies",
            "character-level",
            "code-switching",
            "co-training",
            "contrastive hashing",
            "corpus statistics",
            "cross-lingual word embeddings",
            "data compression",
            "dynamic programming",
            "entailment tree",
            "FastText",
            "finite-state machines",
            "floating-point",
            "Formal Concept Analysis",
            "geometric operations",
            "gaze module",
            "geometric operations",
            "graph structures",
            "gradient descent",
            "interpolation augmentation",
            "internal states",
            "joint-learning",
            "kNN",
            "knowledge Graph",
            "lorentz transformation",
            "measurement modeling",
            "model-based approach",
            "modality gap",
            "modality alignment",
            "mcts",
            "mutual information",
            "neural transducer",
            "nonverbal communication",
            "parameter-efficient fine-tuning",
            "pipeline",
            "randomization",
            "randomization model",
            "reverse engineering",
            "rotary position embeddings",
            "scaling parameters",
            "self-supervised learning",
            "sense-aware encoders",
            "shapley values",
            "software quality",
            "spelling correction model",
            "spiking neural network",
            "surprisal",
            "synthetic data",
            "taxonomy",
            "tokenizer inference methods",
            "two-stage training",
            "vector quantization",
            "weight fusion",
            "weight tuning",
            "weight-space",
            "zipf\"s law\", \"zero-shot learning\", \"Zipfs Law\", \"information dissemination\", \"tokenizer\", \"tokenization\"]}"
        ]
    },
    "Template": {
        "A1 Application": [
            "A1 application of B1 to C1",
            "A1 application of C1 to B1",
            "A1 application of B1 using C1",
            "A1 application of B1 with C1",
            "A1 application of B1",
            "A1 application of C1 and C2 to B1",
            "A1 application of C1 to improve B1",
            "A1 application of A2 to B1 using C1",
            "A1 application of B1 to improve C2",
            "A1 application of B1 via C1",
            "A1 application of B1 in C1"
        ],
        "A1 for B1": [
            "A1 for B1 using C1",
            "A1 for B1 with C1",
            "A1 for B1",
            "A1 for B1 in C1",
            "A1 for B1 via C1",
            "A1 framework for B1 using C1",
            "A1 approach to B1 using C1",
            "A1 framework for B1",
            "A1 approach for B1 using C1",
            "A1 framework for B1 with C1",
            "A1 for B1 via A2",
            "A1 for B1 based on C1",
            "A1 for B1 with A2",
            "A1 B1 via C1",
            "A1 and A2 for B1",
            "A1 paradigm for B1 with C1",
            "A1 strategy for B1",
            "A1 for B1 using C1 and C2",
            "A1 model for B1 using C1",
            "A1 model for B1",
            "A1 approach to B1 with C1",
            "A1 framework for B1 generation",
            "A1 on B1 using C1",
            "A1 on predicting B1 and B2 of news media",
            "A1 model for B1 towards A2 and A3",
            "A1 for B1 beyond A2",
            "A1 policy for B1 using C1",
            "An A1 framework for B1",
            "A1 based method for B1 in C1",
            "A1 system for B1 using C1",
            "A1 approach to B1",
            "A1 framework to automate C1 for B1",
            "A1 application of B1: A survey on C1 and approaches",
            "A1 framework towards B1",
            "A1 for B1 by C1",
            "A1 for B1 may backfire in B1",
            "A1 helps B1 with C1",
            "A1 for B1: Mitigating issues in C1 via A2",
            "A1 for faster C1 in B1",
            "A1 Generation for Faster B1",
            "A1 for effective B1",
            "Towards A1 for B1",
            "Towards better utilization of A1 for B1",
            "Towards A1 C1 for B1",
            "A1 is all you need for B1",
            "Leveraging A1 for B1",
            "A1 is the key to unlocking B1 of C1",
            "A1: A modern Python Library for B1"
        ],
        "A1 for C1": [
            "A1 for C1 in B1",
            "A1 for C1",
            "A1 for C1 on B1",
            "A1 for C1 with B1",
            "A1 for C1 via A2",
            "A1 training of C1 for B1",
            "A1 for C1 to improve B1",
            "A1 enhanced C1 for B1",
            "A1 for improving A2 in B1",
            "Designing data and methods of A1 for C1",
            "Aligning C1 for A1 B",
            "A1 Dataset for evaluating C1 in B1"
        ],
        "A1 with C1 for B1": [
            "A1 of C1 for B1",
            "A1 with C1 for B1",
            "A1 C1 for B1",
            "C1 for B1 with A1",
            "A1 of C1 in B1",
            "A1 in C1 for B1",
            "Investigating A1 in C1 for B1",
            "A1 of C1 on B1",
            "A1 perspective on C1 for B1",
            "Enhancing C1 with A1 for B1",
            "Improving C1 with A1 for B1",
            "C1 with A1 for B1",
            "Towards A1 in C1 for B1",
            "Application of A1 to C1 for B1"
        ],
        "A1 Dataset for B1": [
            "A1 dataset for B1",
            "A1 dataset for B1 with C1",
            "A1 dataset for B1 using C1",
            "A1 dataset for B1 of C1",
            "A1 dataset for B1 in C1",
            "A1 dataset of B1 with C1 and C2",
            "A1 dataset for B1 using C1 and C2",
            "A1 dataset of B1 for C1",
            "A1 dataset B1 for C1",
            "Introduce a new dataset B1 with A1 for C1.",
            "Introducing B1 dataset for A1 of C1",
            "B1 in A1: Dataset and Approaches",
            "Introducing B1 dataset for A1 of scientific paper edits",
            "A1: A universal B1 multimodal language model via B1 pre-training and A2"
        ],
        "A1 Study of B1 with C1": [
            "A1 study of C1 in B1",
            "A1 study of B1 with C1"
        ],
        "A1 Benchmark for C1 in B1": [
            "A1 benchmark for C1 in B1",
            "A1 benchmark and fine-tuning of C1 in B1"
        ],
        "A1 in B1 with C1": [
            "A1 in B1 with C1",
            "Towards A1 B1 with C1",
            "Introducing A1 for B1 using C1",
            "Exploring A1 in B1 with C1",
            "Understanding A1 in B1 with C1",
            "Modeling A1 in B1 with C1",
            "Analysis of A1 in B1 with C1",
            "An open-source A1 B1 based on C1",
            "Analysing the impact of A1 on C1 pre-training in B1"
        ],
        "Evaluating C1 in B1 with A1": [
            "Evaluating C1 in B1 with A1",
            "Evaluating C1 on B1 with A1",
            "Assessing C1 in B1 with A1",
            "Benchmarking C1 in B1 with A1",
            "Evaluating A1 of C1 in B1",
            "Assessing A1 comprehension in B1 with C1",
            "Massively Multilingual Evaluation of C1 Representations in B1 with A1"
        ],
        "A1 of B1": [
            "A1 of B1 using C1",
            "A1 of B1 with C1",
            "Investigating A1 of C1 in B1",
            "Application of C1 to B1 for A1",
            "Application of C1 to B1 with A1",
            "A1 application of B1 for C1",
            "Improving B1 of C1 via A1",
            "A1 for evaluating B1 of C1",
            "A1 framework for B1 of C1",
            "A1 evaluation of C1 in B1",
            "Evaluating A1 in B1",
            "Evaluating A1 of B1 with C1",
            "Enhancing A1 of B1 with A2",
            "Introducing B1 as a benchmark for evaluating C1\"s ability in A1\"    ],   \"A1 Method for B1\": [        \"A1 method for B1 using C1\",        \"A1 method for B1 with C1\",        \"A1 method for B1 in C1\",        \"A1 method C1 for B1\",        \"Introducing A1 method for B1 using C1\",        \"A1 method for B1 to improve C1\",        \"A1 method for B1\"    ],    \"A1 B1\": [        \"A1 B1 with C1\",        \"A1 B1 for C1\",        \"A1 B1 for evaluating C1\",        \"A1 B1 benchmark for C1\",        \"A1 B1 benchmark B1 for C1\",        \"Towards A1 B1 via C1\",        \"A1 guided B1\",        \"A1 B1 Benchmark for C1\",        \"Benchmarking A1 in C1 as B1\",        \"Benchmarking A1 of C1 in B1\",        \"Benchmarking B1 for C1 with A1\",        \"Formalizing B1 from A1 perspective\",        \"An A1 B1 Approach Leveraging C1 and C2\",        \"An A1 Approach to Analyze B1 Tasks\",        \"An Investigation of A1 as a Unified Lens to Explain B1 of C1\",        \"Addressing B1 Problem via A1\",        \"Enhancing B1 by Incorporating A1\",        \"A1 analysis of C1 in B1\",        \"A1 formulation of B1\",        \"A1 for improving B1 in C1\",        \"A1 perspective for A2 on B1\",        \"A1 reduces B1 in C1\",        \"Towards A1 B1 C1\",        \"A1 enables B1 in C1\",        \"Can C1 uncover B1 behind A1?\",        \"Evaluating A1 B1s.\",        \"B1 with A1 is all you need\",        \"B1 is just a C1 with A1\"    ],    \"B1 with C1 using A1\": [        \"B1 with A1 using C1\",        \"B1 with C1 using A1\",        \"Improving B1 with C1 using A1\",        \"B1 with A1 for C1\"    ],    \"Improving B1 with A1\": [        \"Advancing B1 with A1 using C1\",        \"Enhancing B1 with A1\",        \"Improving B1 via A1\",        \"Enhancing B1 with A1 for real-world challenges\",        \"Improving B1 with A1 via C1\",        \"Enhancing B1 by Incorporating A1\",        \"Enhancing B1 with A1 and C2\",        \"Leveraging A1 and Theory for B1\",        \"Improving B1 with A1 using C1\",        \"Improving B1 through A1 in C1\",        \"Benchmarking and Improving B1 with C1 for A1\",        \"Enhancing B1 through A1 from C1\",        \"Enhancing B1 through A1 using C1\"    ],    \"Investigating A1 in B1 using C1\": [        \"Exploring A1 in C1 for B1\",        \"Investigating A1 in B1 using C1\",        \"Understanding A1 in B1 with C1\",        \"Modeling A1 in B1 with C1\",        \"Analysis of A1 in B1 with C1\",        \"Understanding and Locating B1 with A1\",        \"Analyzing behaviors of C1 on B1 with A1\",        \"Study of A1 in B1 with C1\"    ],   \"C1 for B1\": [        \"C1 for B1\",        \"A1 in B1 via A2\",        \"A1 in B1\",        \"C1 with A1 for B1\",        \"C1 with A2 for B1\",        \"A1 C2 for B1\",        \"A1 C1 model for B1\",        \"A1 C1 with A2 for B1\",        \"A1 C1 for B1 via C2 and C3\"    ],    \"B1 is just a C1 with A1\": [        \"B1 is just a C1 with A1\",        \"B1 is effective for C1 evaluation\",        \"B1 with A1 is all you need\",        \"B1 in A1: Dataset and Approaches\"    ],    \"A1 perspective\": [        \"A1 perspective for characterizing and detecting B1\",        \"A1 perspective for A2 on B1\",        \"A1 perspective on C1 for B1\"    ],    \"Benchmarking B1\": [        \"Benchmarking B1 for C1: A Different Perspective on Model Evaluation\",        \"Benchmarking B1 on C1 - A A2 Dataset\",        \"Benchmarking B1 for domain B2\"    ],    \"Enhancing A1 via A2\": [        \"Enhancing A1 via A2\",        \"Improving A1 in B1 via A2\",        \"Enhancing A1 in B1 via A2\",        \"A1 with C2 for B1\"    ],    \"Analyzing B1 with C1\": [        \"Analyzing B1 with C1\",        \"Analyzing B1 with C1 given A1\"    ],    \"Revisiting B1\": [        \"Revisiting C2 for B1 in C1 with A1\",        \"Rethinking B1 for C1\",        \"Reformulating B1 as A1 with C1\"    ],    \"Enhancing B1\": [        \"Enhancing B1 via C1\",        \"Enhancing B1 for C1 with A1\",        \"Enhancing B1 models through C1\",        \"Enhancing B1 through A1 in C1\",        \"Enhanced B1 with C1 for B2\",        \"Enhanced B1 with A1\",        \"Enhanced B1 with A1: C1 and C2 Development\",        \"A1: A Dataset and Optimization for B1 of C1\",        \"Advancing B1 through A1 with C1\",        \"Enhancing B1 through A1 from C1\",        \"Enhancing B1 through A1 using C1\"    ],    \"Evaluating C1 in B1\": [        \"Evaluating C1 in B1\",        \"Evaluating C1 bias in B1 with A1\",        \"Revealing A1 challenges of C1 via B1\",        \"Challenges to evaluating C1 in B1 with A1\",        \"Challenges to evaluating C1 in B1 with A1\"    ],    \"A1 evaluation\": [        \"A1 evaluation of C1 in B1\",        \"A1 for evaluating C1 in B1\",        \"Evaluating C1 through A1 in B1\",        \"A1 Dataset for Evaluating B1\",        \"A1 Dataset for evaluating C1 in B1\"    ],    \"Combining C1\": [        \"Combining C1 with C2 for B1\",        \"Combining C1 and C2 for B1 with A1\",        \"Combining C1 using A1 for B1\"    ],    \"Probing C1\": [        \"Probing for B1 in C1 with A1\",        \"Probing C1 for A1 in B1\"    ],   \"B1 with A1\": [        \"B1 with A1\",        \"Benchmarking B1 with A1 based on C1\",        \"Benchmarking B1 with C1 for A1\",        \"Assessing B1 with A1\"    ],    \"Improving B1\": [        \"Improve B1 via A1\",        \"Improving B1 in C1 through A1\",        \"A1 improves B1\",        \"Improving B1 through A1\"    ],    \"Analyzing C1\": [        \"Analyzing C1 Behavior in B1: Unveiling A1 Trends\",        \"Analysis of C1 in B1 with A1\"    ],    \"A1 dataset for B1 via C1\": [        \"A1 dataset for B1 via C1\",        \"A1 for B2 via C1\"    ],    \"Can C1\": [        \"Can C1 do A1 in B1?\",        \"Can C1\"s Performance be Improved on B1 Tasks?",
            "Can C1 serve as B1",
            "Can C1 adapt to diverse goals in B1?",
            "Can C1 be good at B1? Mitigating A1 on B1",
            "Can C1 uncover B1 behind A1?",
            "Can A1 survive B1? On the A2 of C1",
            "Can we achieve high-quality B1 without A1?",
            "A1 of B1 based on C1",
            "A1 of B1 by C1"
        ],
        "A1 approach": [
            "A1 approach for B1 of B2",
            "A1 approach for B2",
            "A1 approach for B1 of C1 models",
            "A1 approach to improve B1 in C1",
            "A1 approach to B1 for A2 languages"
        ],
        "A1 enables B1": [
            "A1 enables B1 from A2 languages",
            "A1 enables B1 in C1"
        ],
        "Defending against B1": [
            "Defending against B1 via A1 with C1",
            "Defending C1 against B1 with A1",
            "Defending C1 against B1 through A1"
        ],
        "A1 for A2": [
            "A1 for A2 C1",
            "A1 for A2 with C1"
        ],
        "A1 and A2": [
            "A1 and A2 training for C1 in B1",
            "Benchmarking and Improving A1 of B1 with A2",
            "Towards A1 and A2 for B1",
            "Addressing A1 and A2 in B1"
        ],
        "Do C1": [
            "Do C1 exhibit A1 effects in B1?",
            "Do C1 discriminate in B1 on the basis of A1?",
            "Do C1 perform A1 B1?",
            "Do C1 Detect and Understand A1 in B1?",
            "Do C1 Have A1 Knowledge in B1?"
        ],
        "C1 for A1": [
            "C1 for A1 in B1",
            "C1 for B1 in A1 languages",
            "C1 reflect A1 in B1"
        ],
        "A1 C1": [
            "A1 C1 model for B1",
            "A1 C1 with A2 for B1",
            "A1 C1 for B1 via C2 and C3"
        ],
        "Improving A1": [
            "Improving A1 of C1 in B1 with A2",
            "Improving A1 in B1 via A2"
        ],
        "A1 improves C1": [
            "A1 improves C1 of B1",
            "A1 improves C1"
        ],
        "Enhancing A1": [
            "Enhancing A1 of C1 without compromising A2",
            "Enhancing A1 with A2: Towards A3 B1 in A4",
            "Enhancing A1 of C1 through A2"
        ],
        "Direct C1": [
            "Direct C1 A1 through A2",
            "Direct Evaluation of C2 in A1 B1 with Knowledge Graphs"
        ],
        "Studying C1": [
            "Study of C1 in B1 with A1",
            "Study of C1 on B1 with A1",
            "Study of C1 capabilities in B1 with A1"
        ],
        "A1 on B1": [
            "A1 on B1",
            "A1 on C1 for B1"
        ],
        "A1 of C1": [
            "A1 of C1 via A2 in C2",
            "A1 of C1 via A2",
            "A1 of C1 with C2"
        ],
        "A1 in C1": [
            "Deep Exploration of A1 in C1",
            "A1 in B1 for C1"
        ],
        "A1 benchmark": [
            "A1 benchmark on B1",
            "A1 benchmark for B1 to C1",
            "A1 benchmark for measuring B1 of C1"
        ],
        "Complex A1": [
            "Complex A1 over B1 on C1",
            "A1 with C1"
        ],
        "A1 for building B1": [
            "A1 for building B1",
            "Developing C1 for language with A1: A Modern Approach to B1 Dataset Construction"
        ],
        "A1 framework": [
            "An A1 framework for B1",
            "An A1 framework for B1"
        ],
        "Efficient C1": [
            "Efficient C1 with A1 for B1",
            "Efficient C1 with A1 in B1"
        ],
        "Efficient A1": [
            "Efficient A1 for B1",
            "Efficient A1 of B1 with A2 C1"
        ],
        "A1 for C1 may backfire in B1": [
            "A1 for C1 may backfire in B1",
            "Are C1 confusing B1?"
        ],
        "B1 via A1": [
            "B1 via A1",
            "B1 via A1 towards B2 with C1"
        ],
        "Leveraging A1": [
            "Leveraging A1 for efficient B1 by using C1",
            "Leveraging A1 for B1"
        ],
        "A1 application": [
            "An A1 application of C1 for B1",
            "A1 application of B1 with A2",
            "A1 application of B1 with C1 and C2",
            "A1 application of B1 with C1",
            "A1 application of C1 for B1",
            "A1 application of B1 with strategy",
            "A1 application of B1 through C1",
            "A1 application of B1 and B2 with C1",
            "Presenting a new task B1 with C1 for A1 application",
            "A1 application of B1 for B2 in C1"
        ],
        "Exploring A1": [
            "Explore A1 at the concept level in C1 for B1",
            "Exploring A1 for B1",
            "Exploring A1 for C1 in B1",
            "Exploring A1 in B1",
            "Exploring C1 based on A1 for B1",
            "Exploring C1 with C2 in B1 with A1",
            "Exploring A1 in C1",
            "Exploring A1 to assess the B1 of C1",
            "Exploring A1 in C1 through B1: Insights from the Dataset",
            "Exploring A1 B1 ability for C1",
            "Exploring the potential of A1 in B1 with C1",
            "Exploring A1 with C1 in B1",
            "Exploring A1 capability of C1 in B1",
            "Exploring A1, A2 and A3 in B1",
            "Exploring the impact of A1 to C1 in B1"
        ],
        "Exploring C1 potential": [
            "Exploring the potential of C1 in B1"
        ],
        "Extending/Extending C1": [
            "Extending C1 with A1 in B1",
            "Extending C1 by A1 on Graphs"
        ],
        "Leveraging C1": [
            "Leveraging C1 and C2 to enhance B1 with A1",
            "Leveraging C1 in A1 B1",
            "Leveraging C1 for learning complex B1 through A1",
            "Leveraging C1 to facilitate B1 with A1"
        ],
        "A1 phenomenon": [
            "A1 phenomenon in B1 with C1"
        ],
        "A1 evaluation": [
            "A1 evaluation metric for B1 using C1"
        ],
        "A1 Benchmark": [
            "A1 Benchmark to evaluate C1 in B1",
            "A1 benchmark in B1 using C1",
            "A1 benchmark for evaluating C1 in B1",
            "A1 benchmark for B1 with C1",
            "A1 benchmark to evaluate C1 in B1",
            "A1 benchmark for assessing A1 of C1 in B1",
            "A1 benchmark B1 with C1",
            "A1 benchmark for promoting AGI in B1 with C1",
            "A1 benchmark for B1"
        ],
        "A1 output": [
            "A1 the output of C1 via A2"
        ],
        "A1 improves A2": [
            "A1 Improves A2 of C1"
        ],
        "A1 application of C1": [
            "A1 application of C1 to generate B1",
            "A1 application of C1 to B1 at scale",
            "A1 application of C1 to B1 yields better performance",
            "A1 application of C1 to B1 using C2",
            "A1 application of C1 to B1, B2, and B3",
            "A1 application of C2 to B1 with C1"
        ],
        "Investigating C1": [
            "Investigating C1 in B1 with A1",
            "Investigating C1\"s behavior on B1 with A1\",    \"Investigating C1 in A1 models for B1 tasks\",    \"Investigating the Capabilities of C1 for B1\"  ],  \"A1 of C1\": [    \"A1 of C1 with A2\",    \"A1 of C1 and their applications in B1\",    \"A1 of C1 in B1 with A2\",    \"A1 of C1 via B1\"  ],  \"Improve A1\": [    \"Improve A1 of B1 via A2\",    \"Improve A1 capabilities based on C1 for B1\"  ],  \"A1 for B1\": [    \"A1 for B1: Fusing C1 with A2\",    \"A1 for better B1\",    \"A1 for B1 using C2\",    \"A1 for B1: A study of C1\",    \"A1 for B1 through C1\",    \"A1 for B1 on C1\"  ],  \"Finding and Editing A1\": [    \"Finding and Editing A1 in C2\"  ],  \"A1 in B1 enables A2\": [    \"A1 in B1 enables A2 B2\"  ],  \"Fine-tuning C1\": [    \"Fine-tuning C1 with C2 for B1\",    \"Fine-tuning C1 for joint A1 of B1\",    \"Fine-tuning C1 with A1 for B1\",    \"A1 fine-tuning for C1 in B1\"  ],  \"Impact of A1\": [    \"The impact of A1 for C1 in B1\",    \"Impacts of A1 on B1 and B2\",    \"Investigating the Impact of A1 of C1 in B1\",    \"Investigating the Impact of A1 on B1 and A2\",    \"Assessing the impact of A1 on B1\",    \"Investigating the impact of A1 in B1 on C1\",    \"Impact of A1 on A2 in C1\",    \"On the Effect of A1 in B1\",    \"On the impact of A1 in B1\"  ],  \"A1 B1 using C1\": [    \"A1 B1 using C1\"  ],  \"A1 strategies\": [    \"A1 strategies for B1\",    \"An Analysis of A1 Strategies in B1 with C1\"  ],  \"Interpreting and Mitigating A1\": [    \"Interpreting and Mitigating A1 problems in B1 with C1\"  ],  \"Proposing A1\": [    \"Proposing A1 defense method using C1 for B1\",    \"Proposing A1 method for B1 task using C1\"  ],  \"Enhancing A1\": [    \"Enhancing A1 of C1 for effective B1\",    \"Enhancing A1 for C1 in B1\"  ],  \"Combining C1\": [    \"Combining C1 and C2 in B1 with A1\"  ],  \"A1 improves B1\": [    \"A1 improves B1 with C1\",    \"A1 improves B1 of C1\"  ],  \"Constructing C1\": [    \"Constructing C1 with C2 for A1 B1\",    \"Constructing and Serving C1 for B1 with A1\"  ],  \"Refreshing C1\": [    \"Refreshing C1 with A1 for B1\"  ],  \"From C1 to A1\": [    \"From C1 to A1: A2 as a Metric for B1 in C1-based Applications\"  ],  \"Expanding B1\": [    \"Expanding B1 in C1 with A1\"  ],  \"A1 study\": [    \"A1 study on C1 in B1\",    \"A1 case study of C1 in B1\",    \"A1 study on improving B1 performance\"  ],  \"An C1 solution\": [    \"An C1 solution to B1 with A1\"  ],  \"Towards B1\": [    \"Towards B1 of A1 clinical documents\",    \"Towards A1 B1 Evaluation\",    \"Towards building a B1 dataset for A1 languages\",    \"Towards A1 NLP for B1 using C1\",    \"Towards more meaningful evaluations for B1 in C1\",    \"Towards A1 B1 for C1\",    \"Towards systematic evaluation of A1 ability of C1\",    \"Towards enhancing A1 and A2 in B1\"  ],  \"Navigating C2\": [    \"Navigating C2 in B1 with C1\"  ],  \"Human annotation\": [    \"The necessity of human annotation in B1 with A1\"  ],  \"System for B1\": [    \"System for B1 with C1 features\"  ],  \"A1 vs A2\": [    \"A1 vs A2 in B1 with C1\"  ],  \"Generating A1\": [    \"Generating A1 using C1 for A2\",    \"Generating A1 and High-Quality Texts by C1\",    \"Generating A1 Datasets using A1\",    \"Generating and Evaluating A1 Explanations for B1\",    \"Generating B1 Datasets with C1 through A1\"  ],  \"Generating B1\": [    \"Generating B1 for C1 in A1\"  ],  \"To empower C1\": [    \"To empower C1 using tools for B1\"  ],  \"Benchmark for Evaluating C1\": [    \"Benchmark for Evaluating C1 and C2 on B1\"  ],  \"Detecting A1\": [    \"Detecting A1 for C1 in B1\"  ],  \"An A1 of C1\": [    \"An A1 of C1 in B1\"  ],  \"How can C1 adapt\": [    \"How can C1 adapt to A1 B1?\"  ],  \"Highlighting the issues\": [    \"Highlighting the issues of B1 evaluation with C1\"  ],  \"A1 in B1\": [    \"A1 in B1 for B2\"  ],  \"B1 for B2\": [    \"B1 for B2 with A1\"  ],  \"Introducing B1 dataset\": [    \"Introducing B1 dataset and C1 framework for A1\",    \"Introducing B1 dataset for C1 in A1 languages\",    \"Introducing a new dataset B1 with A1 properties for C1 data\",    \"Introducing B1 dataset with A1 and evaluating C1\"  ],  \"A1 for C2\": [    \"A1 for C2 with C1\"  ],  \"Harnessing C1\": [    \"Harnessing C1 as A1\",    \"Harnessing C1 for B1\"  ],  \"Measuring A1\": [    \"Measuring A1 in C1\",    \"Measuring A1 in B1 with A2 from C1\",    \"Measuring A1 in B1 systems\",    \"Measuring and Addressing A1 in B1\",    \"On Measuring A1 or A2 of B1\"  ],  \"LLM Evaluations\": [    \"LLM Evaluations on B1 with A1\",    \"LLMs for B1 with A1\",    \"LLMs can achieve A1 via C1\"  ],  \"How A1 affected\": [    \"How A1 in C1 are affected by B1\"  ],  \"How A1 shape\": [    \"How A1 shape B1?\"  ],  \"Unlocking B1\": [    \"Unlocking B1 with A1\"  ],  \"How good is A1\": [    \"How good is A1 B1 for A2 languages?\"  ],  \"How Important is C1\": [    \"How Important is C1 for B1 with A1?\"  ],  \"Rethinking A1\": [    \"Rethinking A1 to challenge B1 by C1\",    \"Rethinking A1 for B1\",    \"Rethinking A1 B1 Meta-Evaluation\"  ],  \"Comparing C1\": [    \"Comparing C1\"s ability in B1 with A1",
            "Comparing C1 on B1 with A1"
        ],
        "Analysis of A1": [
            "Analysis of A1 in C1",
            "Analysis of A1 in C1 for B1",
            "Analysis of A1\"s effect on B1 using C1\"  ],  \"Comprehensive study\": [    \"Comprehensive study of C1 in B1 with A1\"  ],  \"A1 method\": [    \"A1 method with C1 for B1\",    \"A1 method for C1\",    \"An A1 method for B1 guided by C1\"  ],  \"A1 approach\": [    \"A1 approach for faster B1\",    \"A1 approach for improving B1\",    \"A1 approach to adapt C1 for B1 without A2 supervision\"  ],  \"B1 dataset\": [    \"B1 dataset for testing C1 with A1\",    \"A1 Dataset for B1 with C1\",    \"A1 Dataset for B1 on C1\"  ],  \"Quantifying A1\": [    \"Quantifying A1 for B1\",    \"Quantifying A1 in B1 with C1\",    \"Quantifying A1 in Evaluating B1 Capabilities of C1\",    \"Quantifying A1 in B1 from C1 and Enhancing A2\",    \"Quantifying the effect of A1 in C1 for B1\"  ],  \"Identifying and Improving A1\": [    \"Identifying and Improving A1 in B1\"  ],  \"Improving B1\": [    \"Improving B1 through A1 with C1\",    \"Improving B1 through A1\",    \"Improving B1 with A1 by C1\",    \"Improving B1 with A1\",    \"Improving B1 by utilizing A1 and A2\",    \"Improving B1 with C1\",    \"Improving B1 with C1 through A1\"  ],  \"Unlocking the Power\": [    \"Unlocking the Power of C1 in B1 with A1\"  ],  \"A1 makes C1 robust\": [    \"A1 makes C1 robust in B1\"  ],  \"Introducing a system\": [    \"Introducing a system for B1 with C1 leveraging A1\"  ],  \"Identifying C1\": [    \"Identifying C1 to Understand A1\",    \"Identifying and Mitigating B1 in B2 using A1\",    \"Identifying A1 in C1 in the domain of B1\",    \"Identifying A1 in B1\"  ],  \"Improving C1\": [    \"Improving C1 Generations via A1\",    \"Improving C1 in B1 with A1\",    \"Improving C1 via A1 with constraint\",    \"Improving C1 by A1\",    \"Improving C1 with A1 for C1 in B1\",    \"Improving C1 with A1\"  ],  \"Improving B1 with C1\": [    \"Improving B1 with C1 for A1\"  ],  \"Improving the A1\": [    \"Improving the A1 of B1 via A2 and A3\"  ],  \"Introducing A1\": [    \"Introducing A1 for effective A2 with C1 in B1\",    \"Introducing C1 for B1 based on A1\",    \"Introducing C1 for A1 in B1\",    \"Introducing B1 with A1 for C1\"  ],  \"Evaluating A1\": [    \"Evaluating A1 in B1 through B2\",    \"Evaluating A1 in C1 with B1\",    \"Evaluating A1 in B1 with C1\",    \"Evaluating B1 with A1 using C1\",    \"Evaluating A1 Methods on B1 with C1\",    \"Realistic Evaluation of B1 in C1\",    \"Evaluating B1 with A1 for C1\"  ],  \"Incorporating C1\": [    \"Incorporating C1 and C2 to B1 on C3\"  ],  \"Dataset and Models\": [    \"Dataset and Models for B1 in A1\"  ],  \"A1 for creating B1\": [    \"A1 for creating B1 for C1\"  ],  \"Inducing A1\": [    \"Inducing A1 in C1 by A2\"  ],  \"Characterizing and Recovering A1\": [    \"Characterizing and Recovering A1 in B1\"  ],  \"Benchmarking A1\": [    \"Benchmarking A1 in C1 for B1\",    \"Benchmarking C1 for B1 with A1\"  ],  \"Injecting A1\": [    \"Injecting A1 in C1 for B1\"  ],  \"An A1 tuning framework\": [    \"An A1 tuning framework for B1 using C1\"  ],  \"A1 in B1 through C1\": [    \"A1 in B1 through C1\"  ],  \"Boosting C1\": [    \"Boosting C1 via A1 in B1\",    \"Boosting C1 with Novel A1\",    \"Boosting B1 of C1 with A1\"  ],  \"Aligning B1\": [    \"Aligning B1 and B2 via A1 using C1\",    \"Aligning C1 with B1 using A1\"  ],  \"Advancing A1\": [    \"Advancing A1 through A2\",    \"Advancing C1 for B1 with A1\"  ],  \"C1 are better\": [    \"C1 are better at A1 for B1\"  ],  \"Integrating A1\": [    \"Integrating A1 for B1\",    \"Integrating C1 into C2 with A1\",    \"Integrating C1 and C2 for B1\",    \"A1 for integrating C1 and B1\",    \"Integrating C1 with execution and refinement for B1\"  ],  \"Investigating A1\": [    \"Investigating A1 in B1 of C1\",    \"Investigating A1 in C1 in B1\",    \"Investigating and Mitigating A1 in C1\",    \"Investigating A1 of B1 using C1\",    \"An investigation of how A1 interact with B1 using C1\",    \"Investigation of A1 capabilities in C1\"  ],  \"Generative Evaluation\": [    \"Generative Evaluation of B1 with A1 in C1\"  ],  \"Applying C1\": [    \"Applying C1 to B1 with A1\",    \"Applying C1 to B1 via A1\"  ],  \"C1 can\": [    \"C1 can A1 through A2\",    \"C1 can A1 via C2\",    \"C1 can exploit A1 for B1\",    \"C1 can learn A1 in B1\",    \"C1 Can Learn B1 with A1\"  ],  \"A1 application\": [    \"A1 application of A2 to C1\"  ],  \"A1 C1\": [    \"A1 C1 via B1\",    \"A1 C1 for B1 with A2\",    \"A1 C2 from C1 for B1\"  ],  \"A1: Go Beyond\": [    \"A1: Go Beyond C1 via A2\"  ],  \"A1 Dataset\": [    \"A1 Dataset for B1\",    \"A1 B1 dataset with C1\",    \"A1 Dataset for B1 Created with C1\",    \"A1 Dataset of B1\",    \"A1 Dataset for B1 from Radiology Reports\",    \"A1 Dataset for B1 in conversations\"  ],  \"Enabling B1\": [    \"Enabling B1 in C1 through A1\"  ],  \"Assessing and Advancing B1\": [    \"Assessing and Advancing B1 with C1 using A1\"  ],  \"Enhancing B1\": [    \"Enhancing B1 with C1\",    \"A1 for Enhancing B1 of C1\"  ],  \"Instituting A1 B1\": [    \"Instituting A1 B1 for C1\"  ],  \"A1 neural solver\": [    \"A1 neural solver for B1 problem\"  ],  \"Using C1\": [    \"Using C1 to improve C2 for B1\",    \"Using C1 to enhance A1 via C2\"  ],  \"Open platform\": [    \"Open platform for B1 using C1 and C2\",    \"An open toolkit to enable B1 on C1\"  ],  \"Reviving C1\": [    \"Reviving C1 from larger C1 with A1\"  ],  \"Linguistically-Informed Evaluation\": [    \"Linguistically-Informed Evaluation for B1 with C1\"  ],  \"A1 for A2\": [    \"A1 for A2\",    \"A1: Enabling A2 B1 and A2 Decoding\"  ],  \"Uncovering C1\": [    \"Uncovering C1 through A1 by C2\",    \"Uncovering A1 in B1 of C1\",    \"Uncovering A1 in B1 by A2\",    \"Unlocking A1 of C1 via B1\"  ],  \"Efficient application\": [    \"Efficient application of C1 to B1 with limited memory\"  ],  \"A1 library\": [    \"A1 library for C1 to ease B1\"  ],  \"Teaching C1\": [    \"Teaching C1 to use criteria in B1\"  ],  \"Rethinking C1\": [    \"Rethinking C1\"s function in B1 with A1",
            "Rethinking the bounds of C1 in B1: Are A1 the key?"
        ],
        "Scaling C1": [
            "Scaling C1 with A1 using B1",
            "Scaling Up C1 for B1",
            "Scaling C1 for B1 via A1"
        ],
        "Reformulating B1": [
            "Reformulating B1 with A1 using C1",
            "Refining B1 from a A1 perspective for B1"
        ],
        "Study on C1": [
            "Study on C1\"s A1 ability in B1\",    \"Study of A1 of C1 in B1\"  ],  \"Improved B1 system\": [    \"Improved B1 system leveraged by C1 with A1\"  ],  \"Interactive Tool\": [    \"Interactive Tool for Analyzing C1 in B1\"  ],  \"C1 as A1\": [    \"C1 as A1 B1 by C2\",    \"C1 as C2 for A1 B1\",    \"C1 as C2 for B1\",    \"C1 as a judge for B1\",    \"Introducing C1 as A1 for B1\"  ],  \"We investigate\": [    \"We investigate what linguistic factors affect the performance of B1 models.\"  ],  \"A1 and A2\": [    \"A1 and A2 for B1: A Case Study\",    \"A1 and A2 method for C1 in B1\"  ],  \"Empirical investigation\": [    \"Empirical investigation of A1 in B1 with C1\"  ],  \"A1 of C1 through C2\": [    \"A1 of C1 through C2 for B1\"  ],  \"Analyzing and improving\": [    \"Analyzing and improving C1 on B1 with A1\",    \"Analyzing C1 with A1 property for B1\"  ],  \"Large Language Models\": [    \"Large Language Models as A1 B1 through C2\"  ],  \"A1 C2\": [    \"A1 C2 for B1 of C1\"  ],  \"Learning A1\": [    \"Learning A1 with C1\",    \"Learning A1 of B1 via C1\",    \"Learning A1 grounded citations for C1 for B1\",    \"Learning A1 from B1 with C1\",    \"Learning A1 B1 via C1\",    \"Learning A1 with C1 and C2\",    \"Learning A1 of B1 for B1\",    \"A1 Learning for B1\"  ],  \"Learning B1\": [    \"Learning B1 in C1 with A1\"  ],  \"Rethinking B1\": [    \"Rethinking B1 with A1 in C1\",    \"Rethinking B1: From complex modularity to A1\",    \"Revisiting B1 as A1\"  ],  \"Learning to do something\": [    \"Learning to do something with C1\",    \"Learning to do B1 with C1 via A1\",    \"Learning to A1 for B1\",    \"Learning to A1 for C1 B1\",    \"Learning to do X with Y\",    \"Learning to A1 for B1 of C1\"  ],  \"Leveraging A1\": [    \"Leveraging C2 and C1 for A1 B1\",    \"Leveraging A1 for B1 using C1\",    \"Leveraging A1 for B1: The A2-Guided B1\",    \"Leveraging A1 in B1\"  ],  \"Enhance B1\": [    \"Enhance B1 with A1\"  ],  \"Mitigation of A1\": [    \"Mitigation of A1 in C1 for B1\",    \"Mitigating A1 in B1 from C1 by paying attention to A2\",    \"Mitigating A1 and A2 for B1 in the Era of C1\",    \"Mitigating A1 in B1 with C1 and its Dataset\",    \"Mitigating A1 in C1 via B1\",    \"Mitigating A1 in C1 with A2\",    \"Mitigating A1 in C1 via B1\"  ],  \"Limits of A1\": [    \"Limits of A1 in B1\"  ],  \"A1 the B1\": [    \"A1 the B1 using C1\"  ],  \"A1 package\": [    \"A1 package for B1 with C1\"  ],  \"C1 improves A1\": [    \"C1 improves A1 B1\"  ],  \"Unified A1\": [    \"Unified A1 of C1 for B1\"  ],  \"A1 meets A2\": [    \"A1 meets A2 in B1\",    \"A1 meets B1 on C1\"  ],  \"Locating and Extracting A1\": [    \"Locating and Extracting A1 in C1 for B1\"  ],  \"Introducing B1\": [    \"Introducing B1 to evaluate C1 with A1\",    \"Introducing B1 for evaluating C1 with A1\"  ],  \"Accelerating and Enhancing C1\": [    \"Accelerating and Enhancing C1 in A1 via C2\"  ],  \"Can C1 understand\": [    \"Can C1 understand A1?\"  ],  \"How C1 evaluate\": [    \"How C1 evaluate B1 with A1\"  ],  \"A1 for B1 in C1\": [    \"A1 for B1 in C1 via B2\",    \"A1 for C1-based B1\",    \"A1 for B1 to improve C1\"  ],  \"A1 benchmark B1\": [    \"A1 benchmark B1 with C1\"  ],  \"Evaluation Benchmark\": [    \"Evaluation Benchmark for B1 with A1\",    \"B1 evaluation benchmark for C1\"  ],  \"B1 in A1\": [    \"B1 in A1\"  ],  \"B1 of A1\": [    \"B1 of A1 of C1\"  ],  \"Completing B1\": [    \"Completing B1 with A1 using C1\"  ],  \"A comprehensive B1\": [    \"A comprehensive B1 of C1 in specific domain\"  ],  \"A1 using A2\": [    \"A1 using A2 for B1\"  ],  \"Recent advances\": [    \"Recent advances in A1 C1\"  ],  \"The case of B1\": [    \"The case of B1 in A1\"  ],  \"A1 dataset\": [    \"A1 dataset for B1 in B2\",    \"A1 dataset for B1 in conversations\",    \"A1 B1 dataset\"  ],  \"A1 for better\": [    \"A1 for better and fairer B1 using C1\",    \"A1 for better B1 of C1\"  ],  \"A1 framework\": [    \"A1 framework for C1 in B1\",    \"A1-based framework for advancing B1 via B2\",    \"A1 framework for B1 based on C1\",    \"A1 framework for B1 via C1\",    \"A1 framework and dataset for B1 modeling with C1\"  ],  \"Making C1 better\": [    \"Making C1 better at A1 in B1\"  ],  \"A1 can improve\": [    \"A1 can improve B1 of C1\"  ],  \"A1 with C1\": [    \"A1 with C1 in C2: A cross-lingual exploration of B1\",    \"B1 with C1 for A1\"  ],  \"Method and Evaluation\": [    \"Method and Evaluation for C1-Based A1 B1\"  ],  \"A1 of C1 in B1\": [    \"A1 of C1 in B1: A2 and a method\"  ],  \"Measuring A1 in B1\": [    \"Measuring A1 in B1 with A2 from C1\",    \"Measuring C1 in B1 with A1\"  ],  \"Examining C1\": [    \"Examining C1 in B1 with A1\",    \"Examining C1 performance on B1 with A1\"  ],  \"Efficient C1\": [    \"Efficient C1 for B1 using A1\",    \"Efficient B1 with A1\",    \"Efficient A1 with C1 in B1\"  ],  \"Meta-Tuning C1\": [    \"Meta-Tuning C1 to Leverage C2 for Generalizable B1 Understanding\"  ],  \"B1 dataset for C1\": [    \"B1 dataset for C1 with A1\"  ],  \"A1 sparks A2\": [    \"A1 sparks A2 in C1 for B1\"  ],  \"C1 in B1 with A1\": [    \"C1 in B1 with A1\"  ],  \"Mitigating B1\": [    \"Mitigating B1 for C1 via A1\",    \"Mitigating B1 in C1 via C2\",    \"Mitigating A1 in B1 based on C1\"  ],  \"Modeling B1\": [    \"Modeling B1 utilizing C1 and A1\"  ],  \"Modelling A1\": [    \"Modelling A1 with C1 for B1\",    \"Modeling A1 with A2 for B1\",    \"A1 modeling of B1 with C1\"  ],  \"Representation of A1\": [    \"Representation of A1 in C1 for B1\"  ],  \"Assessing C1\": [    \"Assessing C1\"s A1 in B1",
            "Assessing A1 for B1"
        ],
        "Observing relationship": [
            "Observing relationship between A1 and A2 in B1 using C1"
        ],
        "Challenging C1": [
            "Challenging C1 with B1 using A1"
        ],
        "A1 retrieval": [
            "A1 retrieval for C1 based B1"
        ],
        "A1 remedies": [
            "A1 remedies degradation of B1 on C1"
        ],
        "New Datasets": [
            "New Datasets and Model for B1 with A1 using C1"
        ],
        "A1 B1 corpus": [
            "A1 B1 corpus for C1"
        ],
        "A1 question": [
            "A1 question in B1"
        ],
        "A1 framework for C1": [
            "A1 framework for C1 at B1"
        ],
        "A1 system": [
            "A1 system for B1 in domain B2"
        ],
        "Dynamic B1": [
            "Dynamic B1 on A1 ability of C1"
        ],
        "Exploring B1": [
            "Exploring B1 and evaluating C1 for A1",
            "Exploring the A1 of C1 in B1"
        ],
        "A1 algorithm": [
            "A1 algorithm for C1 in B1",
            "A1 algorithm for augmenting C1 with B1"
        ],
        "Mastering B1": [
            "Mastering B1 with A1 via C1"
        ],
        "A1 for assessing": [
            "A1 for assessing C1 in B1",
            "A1 for assessing C1\"s capabilities in B1\"  ],  \"Filling the gap\": [    \"Filling the gap in B1 with A1\"  ],  \"A1 of C1-Centric Agents\": [    \"A1 of C1-Centric Agents in B1\"  ],  \"On A1\": [    \"On A1 in B1 with C1\",    \"On A1 and A2 B1 for data annotation\",    \"On A1 Representing B1 as C1\",    \"On the A1 of C1 with A1\",    \"On the A1 of B1 Models to C1\",    \"On the role of A1 in B1 with C1\",    \"On the A1 of C1 in B1\",    \"On the A1 of A2 in C1\"  ],  \"On the Evaluation\": [    \"On the Evaluation of C1 for B1\"  ],  \"On the relationship\": [    \"On the relationship between C1 and B1 with A1\"  ],  \"Challenges and Benchmark\": [    \"Challenges and Benchmark Construction for B1 with C1 in A1\"  ],  \"Overcoming A1\": [    \"Overcoming A1 by A2 in B1\",    \"Overcoming A1 of C1 with A2\"  ],  \"A1 yields A2\": [    \"A1 yields A2 in C1\"  ],  \"B1 for A1 Languages\": [    \"B1 for A1 Languages using C1\"  ],  \"Mining A1\": [    \"Mining A1 for B1 in C1\"  ],  \"An approach for B1\": [    \"An approach for B1 in B2 with C1\"  ],  \"A1 to enhance B1\": [    ",
            "A1 to enhance B1 using C"
        ],
        "Improving A1 of B1": [
            "Improving A1 of B1 in C1",
            "Towards better A1 in B1",
            "A1 to improve B1 in C1"
        ],
        "A1 in B1": [
            "Benchmarking A1 in B1",
            "Towards A1 in B1",
            "Towards A1 B1 at Scale",
            "Exploring A1 in B1 for C1",
            "Exploring A1 in B1 using C1",
            "Understanding A1 in B1",
            "Investigating A1 in B1",
            "Understanding A1 - A B1",
            "Analyzing A1 in B1 for C1",
            "Dissecting B1 with A1",
            "Understanding A1 in B1",
            "Exploration of A1 in B1 of C1",
            "Investigating A1 in B1 with C1",
            "Exploring A1 of C1 in B1",
            "Analyzing A1 in B1 using C1",
            "Exploring A1 Issues in B1",
            "Exploring A1 and A2 in B1 with C1",
            "Impact of A1 on B1 with C1",
            "Towards A1 in B1 for C1",
            "A1 analysis of B1 in B2",
            "Towards better understanding of B1 with A1: A unified paradigm for C1",
            "Understanding A1 for B1 with C1",
            "Towards A1 B1 incorporating C1",
            "Exploring A1 in B1",
            "Analysis of A1 in B1 using C1",
            "A1 in B1: a survey from C1, C2, and C3"
        ],
        "A1 with C1": [
            "A1 framework integrating C1 and C2 for B1",
            "A1 and A2 C1 for B1",
            "A1 evaluation method for B1 with C1",
            "Generating A1 empathetic responses in B1 with C1",
            "A1 Module for B1 with C1",
            "B1 with A1 on C1",
            "Reducing A1 in B1 with C1",
            "Analysis of A1 methods for B1 with C1",
            "Pioneering A1 B1 with C1",
            "Improving B1 with A1 Using C1",
            "Improving B1 with A1 at A3 for C1",
            "Probing C1 in B1 with A1",
            "A1 approach to B2 using C1",
            "Simplifying B1 with A1 using C1",
            "A1: A framework for exploring B1 with C1",
            "Enhancing B1 with C1 A1",
            "A1 approach to B1 using C1 and C2",
            "A1 via C1 with B1",
            "Help A1 become a better teacher to instruct C1 in B1",
            "A1 improves C1 in B1",
            "The impact of C2 on C1 in B1 with A1",
            "Characterization and Generation for Understanding Capability of C1 in B1",
            "Tackling A1 in B1 with C1",
            "What is There and What is Missing in B1 with C1 and C2?",
            "Application of C1 to B1 using A1",
            "How is C1 affecting B1 with A1: A case study",
            "Identifying C1 in B1 with A1",
            "A1 attack on C1 in B1",
            "A1 makes C1 reliable B1",
            "Problem of A1 in C1 and a solution",
            "Stress testing A1 of B1 under C1",
            "A1 data filtering for B1 using C1",
            "A1 for efficient training of C1 in B1",
            "Introducing a new task of B1 with A1 and addressing it with C1",
            "Evaluating A1 for C1 in B1",
            "Introducing C1 for B1 in A1",
            "Evaluating the ability of C1 and C2 in B1 with A1",
            "Teaching C1 to B1 through A1",
            "Towards A1 of B1 driven by C1",
            "Prediction of A1 in B1 using C1",
            "Introducing a new model for B1 using A1 with C1",
            "How A1 affects C1 in B1",
            "An A1 on B1 in C1",
            "Introducing A1 training method for C1 in B1",
            "Towards A1 B1 incorporating C1",
            "Analysis of C1 for B1 with A1",
            "The Impact of A1 on C1 in B1",
            "Formulating A1 for C1 in B1",
            "The B1 Dataset and a C1-Based Approach for B1",
            "The Power of A1-C1 in B1",
            "A1 metric for A2 in C1",
            "A1 evaluation of B1 abilities in C1",
            "Analyzing C1 with A1 in B1",
            "Towards A1 C1 for B1",
            "Towards better A1 B1 via C1",
            "Towards A1 in B1 for C1",
            "Leveraging A1 for B1 with C1",
            "A1 framework for B1 in C1",
            "Training C1 for B1 with A1",
            "Training C1 for B1 via A1",
            "A1 framework to address the B1 in C1",
            "Using C1 for B1 with A1",
            "Tuning C1 for B1 using A1",
            "Human evaluation of C1 A1 in B1",
            "Unveiling A1 of C1 in B1",
            "Understanding A1 for B1 with C1",
            "Understanding and Patching A1 B1 in C1",
            "Impact of A1 on B1 using C1",
            "A1 to improve B1 in C1",
            "Unlocking A1 B1 with C1",
            "Unraveling and Mitigating A1 in B1 with C1",
            "A1 via C1 using A2 and A3",
            "A1 approach for B2 using C1",
            "Towards C1-based A1 of B1",
            "Enhancing B1 through A1 with C1",
            "A1 analysis on B1 using C1",
            "A1: A C1-Based Framework for B1",
            "Analysis of C1 on B1 with A1",
            "A1 method for B1 of C1",
            "Towards A1 of B1 for C1",
            "Aligning C1 in B1 with A1",
            "A1 benchmark for B1 using C1",
            "Leveraging C1 for B1 via A1",
            "A1 pre-training for B1 with C1",
            "B1 dataset with A1 using C1 and humans",
            "Adapting C1 for A1 in B1",
            "Analyzing C1 in B1 using A1",
            "A1 framework driven by C1 for B1",
            "A1 of B1 in C1",
            "How do we predict A1 in B1?"
        ],
        "Towards A1": [
            "Toward A1 B1",
            "Towards A1 of C1 in B1",
            "Towards A1 on B1 of C1",
            "Towards A1 Style Learning for B1",
            "Towards A1 interface for C1",
            "Towards A1 and A2 C1 for B1",
            "Towards A1 through A2"
        ],
        "B1 using A1": [
            "B1 using A1",
            "Synthesizing B1 from unlabeled data using A1",
            "Using A1 to improve A2 of C1 in B1"
        ],
        "Evaluating A1": [
            "Evaluating A1 and its Correlation with B1",
            "Introducing C1 metrics for evaluating A1 in C1"
        ],
        "A1 dataset": [
            "A1 dataset of B1",
            "A1 dataset of B2 for B2",
            "Introducing B1 dataset for A1 with C2",
            "An A1 dataset for B1 on C1"
        ],
        "B1 with C1": [
            "Introducing a new task of B1 with A1 and addressing it with C1",
            "What is There and What is Missing in B1 with C1 and C2?",
            "What are we missing in B1 with C1?",
            "What B1 Do C1 Find A1?",
            "What makes C1 good-enough for B1?",
            "What have we achieved on B1?",
            "What Influences B1 with A1?",
            "Why B1 is hard for C1"
        ],
        "Teaching C1": [
            "Teaching C1 to A1 by learning from B1",
            "Teaching C1 an unseen B1 with A1",
            "Teaching C1 to do B1 with A1",
            "What is the Best Way for C1 to B1?"
        ],
        "B1 exploration": [
            "B1 exploration in natural language with A1",
            "Unveiling B1 via A1 for B1"
        ],
        "A1 decoding": [
            "A1 decoding of C1 for B1",
            "A1 for faster C1 in B1"
        ],
        "Analyzing C1": [
            "Unveiling A1 regions in C1",
            "Study C1 through the lens of A1",
            "Whose A1 do C1 reflect in B1?"
        ],
        "Towards A1 B1": [
            "Towards A1 B1",
            "Towards A1 B1 of C1 at the action level",
            "Towards A1 B1 of C1 via a B2 Dataset and Pseudo-Instruction Tuning"
        ],
        "Towards A1 C1": [
            "Towards A1 C1 through B1",
            "Towards A1 C1 for B1"
        ],
        "Improving B1": [
            "Improving B1 with A1",
            "Improving B1 from C1 with A1"
        ],
        "A1 method": [
            "A1 method for C1 in B1",
            "A1 method for improving B1 in C2",
            "A1 method to address observation in B1 with C2",
            "A1 method for B1 of C1"
        ],
        "Benchmarking B1": [
            "Benchmark B1 with reevaluation A1 and future challenges",
            "Benchmarking B1 in C1",
            "Benchmarking B1 using A1"
        ],
        "Facilitating A1": [
            "Facilitating A1 via C1 in B1"
        ],
        "Injecting A1": [
            "Injecting A1 into C1 for B1 by simulation"
        ],
        "A1: Defending": [
            "A1: Defending against B1 via A2"
        ],
        "Impact of A1": [
            "Impact of A1 on C1 in B1",
            "Impact of A1 on A2 of C1 in B1"
        ],
        "Introducing B1": [
            "Introducing B1 benchmark with A1 for C1",
            "Introducing B1 with A1 for real-world scenarios.",
            "Introducing B1 task with A1 and baselines."
        ],
        "Self- from C1": [
            "Self- from C1 make small B1 better"
        ],
        "B1 from B2": [
            "B1 from B2 via A1 learning"
        ],
        "A1 perspective": [
            "A1 perspective for B1 in A2"
        ],
        "Theoretical puzzle": [
            "Theoretical puzzle about the relationship between A and B"
        ],
        "Structuring B1": [
            "Structuring B1 for the present and navigating the future of A1"
        ],
        "B1 A1 of C1": [
            "B1 A1 of C1"
        ],
        "Unexpected phenomenon": [
            "Unexpected phenomenon of C1 in B1"
        ],
        "Unified approach": [
            "Unified approach to A1 detection in C1 for B1"
        ],
        "Unlocking A1 B1": [
            "Unlocking A1 B1 with C1"
        ],
        "Towards Comprehensively Evaluating": [
            "Towards Comprehensively Evaluating A1 and Understanding of C1"
        ],
        "Bridging C1 and A1": [
            "Bridging C1 and A1 with C2"
        ],
        "Enhancing B1": [
            "Enhancing B1 in language with a unified C1 model"
        ],
        "Probing C1": [
            "Probing C1 for A1 representations in B1"
        ],
        "What Do Language Models Learn": [
            "What Do Language Models Learn in Context?"
        ],
        "What does A1 uncover?": [
            "What does A1 of B1 really uncover?"
        ],
        "Opportunities and Risks": [
            "Opportunities and Risks of C1 in B1"
        ],
        "Revealing A1": [
            "Revealing A1 of C1 in B1"
        ],
        "When to use B1": [
            "When to use B1 to improve C1 with A1"
        ],
        "The Importance of C1": [
            "The Importance of C1 in B1 with A1"
        ],
        "Interpreting C1": [
            "Interpreting C1 through A1"
        ],
        "Enabling B1": [
            "Enabling B1 with C1 using A1"
        ],
        "When is C2 useful": [
            "When is C2 useful for C1 in B1? It depends on the discriminator."
        ],
        "Two issues": [
            "Two issues with B1 and A1 solution"
        ],
        "A1 based": [
            "A1 based B1 of C1 agents"
        ],
        "A1 B1 through": [
            "A1 B1 through A2 C1"
        ],
        "A1 platform": [
            "A1 platform for B1 for C1"
        ],
        "An Examination": [
            "An Examination of B1 with A1"
        ],
        "A1 constrained": [
            "A1 constrained learning for B1"
        ],
        "A1: A Benchmark": [
            "A1: A Benchmark for C1 Attribution"
        ],
        "A1 is encoded": [
            "A1 is encoded in the weights of C1"
        ],
        "A1 pre-training": [
            "A1 pre-training towards B1"
        ],
        "Standardization and Exploration": [
            "Standardization and Exploration of B1 with A1"
        ],
        "A1 metric": [
            "A1 metric for A2 in C1"
        ],
        "A1 improves": [
            "A1 improves C1\"s B1 capabilities\"    ],    \"A1 through\": [        \"A1 through C2\"    ],    \"A1 B1 from\": [        \"A1 B1 from C2\"    ],    \"A1 system\": [        \"A1 system for B1\"    ],    \"Discussing A1\": [        \"Discussing A1 in the context of B1\"    ],    \"The state of B1 data quality\": [        \"The state of B1 data quality: Is bigger always better?\"    ],    \"The A1 of A2\": [        \"The A1 of A2 for B1\"    ],    \"What A1 are easy\": [        \"What A1 are easy to B1?\"    ],    \"A1 benchmark\": [        \"A1 benchmark for diagnosing A2 in C1 for B1\"    ],    \"A1 makes C1 reliable\": [        \"A1 makes C1 reliable B1\"    ],    \"A1: Simple\": [        \"A1: Simple and Highly A2 by Learning to C1\"    ],    \"A1 improves C1\": [        \"A1 improves C1 in B1\"    ],    \"Serving C2-based C1\": [        \"Serving C2-based C1 with A1\"    ],    \"Do C1 Really Understand\": [        \"Do C1 Really Understand B1?\"    ],    \"Can C1 grasp\": [        \"Can C1 grasp A1 of B1?\"    ],    \"Investigating C1\"s belief\": [        \"Investigating C1\"s belief towards A1 via A2 B1\"    ],    \"Tracing A1 shifts\": [        \"Tracing A1 shifts of B1 during C1 fine-tuning\"    ],    \"Dissecting B1 challenges\": [        \"Dissecting B1 challenges of C1 in A1 contexts\"    ],    \"Detecting C1-generated texts\": [        \"Detecting C1-generated texts through A1\"    ],    \"Toward A1 in B1\": [        \"Toward A1 in B1: Adapting C1 to a specific state\"    ],    \"Towards B1 in C1\": [        \"Towards B1 in C1 with A1\"    ],    \"Understanding and Addressing\": [        \"Understanding and Addressing the B1 Problem from the Perspective of A1\"    ],    \"Understanding the impacts\": [        \"Understanding the impacts of B1 on A1 speakers\"    ],    \"A1 analysis\": [        \"A1 analysis of B1 in B2\"    ],    \"Introducing B1 with\": [        \"Introducing B1 with A1 for real-world scenarios.\"    ],    \"Enhancing C1\": [        \"Enhancing C1 with C2 for B1\"    ],    \"What B1 Do C1 Find\": [        \"What B1 Do C1 Find A1?\"    ],    \"Why observation\": [        \"Why observation in B1 with C2\"    ],    \"Extending B1 evaluation\": [        \"Extending B1 evaluation with A1\"    ],  \"Leveraging C1\": [    \"Leveraging C1 to decide when and what to retrieve for C2 in B1\",    \"Leveraging C1 for B1\"  ],  \"C1 can be used to select data\": [    \"C1 can be used to select data for C2 in B1\"  ],  \"B1 dataset\": [    \"B1 dataset in A1 setting for evaluating C1 and C2\"  ],  \"Unleashing C1\"s Potential\": [    \"Unleashing C1\"s Potential for B1 through A1\"  ],  \"Uncovering the potential\": [    \"Uncovering the potential of C1 in B1\"  ],  \"Steering C1\": [    \"Steering C1 via A1\"  ],  \"A1 makes\": [    \"A1 makes C1 reliable B1\""
        ]
    }
}